"""
ç™½åå–®åˆ†æèˆ‡æ‡‰ç”¨æ¨¡çµ„

æä¾› False Positive æ¨¡å¼åˆ†æå’Œç™½åå–®è¦å‰‡æ‡‰ç”¨åŠŸèƒ½ã€‚
ä½¿ç”¨é¡åˆ¥å°è£ï¼Œéµå¾ªå–®ä¸€è·è²¬åŸå‰‡ï¼Œå¯ç¨ç«‹ä½¿ç”¨ã€‚

ä½¿ç”¨ç¯„ä¾‹ï¼š
    >>> import pandas as pd
    >>> import numpy as np
    >>> from src.whitelist import WhitelistAnalyzer, WhitelistApplier
    >>> 
    >>> # æº–å‚™è³‡æ–™ï¼ˆåªéœ€è¦åŒ…å«å¿…è¦æ¬„ä½çš„ DataFrameï¼‰
    >>> features_df = pd.DataFrame({
    ...     'Proto': ['TCP', 'UDP', 'TCP'],
    ...     'Dport': [80, 53, 443],
    ...     'DstAddr': ['192.168.1.1', '8.8.8.8', '10.0.0.1']
    ... })
    >>> y_pred = np.array([1, 1, 0])  # é æ¸¬çµæœ
    >>> y_true = np.array([0, 0, 0])  # çœŸå¯¦æ¨™ç±¤ï¼ˆå¯é¸ï¼‰
    >>> 
    >>> # åˆ†æ FP æ¨¡å¼
    >>> analyzer = WhitelistAnalyzer(verbose=False)
    >>> rules = analyzer.analyze_fp_patterns(features_df, y_pred, y_true)
    >>> isinstance(rules, list)
    True
    >>> 
    >>> # æ‡‰ç”¨è¦å‰‡
    >>> applier = WhitelistApplier(verbose=False)
    >>> y_filtered, stats = applier.apply_rules(y_pred, features_df, rules)
    >>> len(y_filtered) == len(y_pred)
    True
"""

from typing import List, Tuple, Optional, Dict, Any, Union
import pandas as pd
import numpy as np
import ipaddress
import json
from pathlib import Path
from enum import Enum


class WhitelistRuleType(Enum):
    """ç™½åå–®è¦å‰‡é¡å‹"""
    PROTO_PORT = "proto_port"
    PROTO_PORT_BEHAVIORAL = "proto_port_behavioral"
    PROTO_IP = "proto_ip"
    PROTO_PORT_IP = "proto_port_ip"
    PROTO_PORT_RANGE = "proto_port_range"
    PORT = "port"
    PORT_BEHAVIORAL = "port_behavioral"


class WhitelistAnalyzer:
    """
    ç™½åå–®è¦å‰‡åˆ†æå™¨
    
    åˆ†æè¨“ç·´é›†ä¸Šçš„ False Positives æ¨¡å¼ï¼Œæ­¸ç´ç™½åå–®è¦å‰‡ã€‚
    çµåˆå”è­°ã€ç«¯å£ã€IP ç­‰ç¶²è·¯å±¤è³‡è¨Šã€‚
    å¯ç¨ç«‹ä½¿ç”¨ï¼Œåªéœ€æä¾›åŒ…å«å¿…è¦æ¬„ä½çš„ DataFrame å’Œé æ¸¬çµæœã€‚
    
    å¿…è¦æ¬„ä½ï¼š
        - Proto: å”è­°ï¼ˆå¦‚ 'TCP', 'UDP'ï¼‰
        - Dport: ç›®æ¨™ç«¯å£
        - DstAddr: ç›®æ¨™ IPï¼ˆå¯é¸ï¼Œç”¨æ–¼ IP ç›¸é—œè¦å‰‡ï¼‰
        - SrcAddr: ä¾†æº IPï¼ˆå¯é¸ï¼‰
    
    å¯é¸æ¬„ä½ï¼ˆç”¨æ–¼è¡Œç‚ºç‰¹å¾µåˆ†æï¼‰ï¼š
        - TotBytes, TotPkts, SrcBytes, DstBytes, Dur ç­‰
    
    >>> import pandas as pd
    >>> import numpy as np
    >>> 
    >>> # å‰µå»ºæ¸¬è©¦è³‡æ–™
    >>> df = pd.DataFrame({
    ...     'Proto': ['TCP', 'UDP', 'TCP'],
    ...     'Dport': [80, 53, 443]
    ... })
    >>> y_pred = np.array([1, 1, 0])
    >>> y_true = np.array([0, 0, 0])
    >>> 
    >>> analyzer = WhitelistAnalyzer(verbose=False)
    >>> rules = analyzer.analyze_fp_patterns(df, y_pred, y_true)
    >>> isinstance(rules, list)
    True
    """
    
    def __init__(
        self,
        fp_ratio_threshold: float = 0.05,
        normal_ratio_threshold: float = 0.01,
        attack_ratio_threshold: float = 0.05,
        anomaly_score_threshold: Optional[float] = None,
        use_scoring_method: bool = False,  # ğŸ”§ æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨è©•åˆ†æ–¹æ³•ï¼ˆé è¨­ Falseï¼Œä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        top_n_combos: int = 20,  # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨è©•åˆ†æ–¹æ³•æ™‚ï¼Œé¸æ“‡ Top-N å€‹çµ„åˆ
        min_combo_samples: int = 50,  # ğŸ”§ æ–°å¢ï¼šæœ€å°æ¨£æœ¬é‡è¦æ±‚
        score_threshold: Optional[float] = None,  # ğŸ”§ æ–°å¢ï¼šè©•åˆ†é–¾å€¼ï¼ˆå¯é¸ï¼Œèˆ‡ top_n_combos äºŒé¸ä¸€ï¼‰
        verbose: bool = True
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            fp_ratio_threshold: FP ä½”æ¯”é–¾å€¼ï¼ˆä½¿ç”¨é–¾å€¼æ–¹æ³•æ™‚ï¼Œè¶…éæ­¤å€¼æ‰è€ƒæ…®åŠ å…¥ç™½åå–®ï¼‰
            normal_ratio_threshold: æ­£å¸¸æµé‡ä½”æ¯”é–¾å€¼ï¼ˆåœ¨æ­£å¸¸æµé‡ä¸­ä¹Ÿå¸¸è¦‹æ‰åŠ å…¥ç™½åå–®ï¼‰
            attack_ratio_threshold: æ”»æ“Šè€…ä½”æ¯”é–¾å€¼ï¼ˆè¦å‰‡åŒ¹é…çš„æµé‡ä¸­ï¼Œæ”»æ“Šè€…æ¯”ä¾‹ä¸èƒ½è¶…éæ­¤å€¼ï¼‰
            anomaly_score_threshold: ç•°å¸¸åˆ†æ•¸é–¾å€¼ï¼ˆå¯é¸ï¼Œåªå°ä½åˆ†æ•¸æµé‡æ‡‰ç”¨ç™½åå–®ï¼‰
            use_scoring_method: æ˜¯å¦ä½¿ç”¨è©•åˆ†æ–¹æ³•ï¼ˆTrueï¼‰æˆ–å›ºå®šé–¾å€¼æ–¹æ³•ï¼ˆFalseï¼Œé è¨­ï¼‰
            top_n_combos: ä½¿ç”¨è©•åˆ†æ–¹æ³•æ™‚ï¼Œé¸æ“‡ Top-N å€‹çµ„åˆï¼ˆé è¨­ 20ï¼‰
            min_combo_samples: æœ€å°æ¨£æœ¬é‡è¦æ±‚ï¼ˆç¢ºä¿çµ±è¨ˆå¯é æ€§ï¼Œé è¨­ 50ï¼‰
            score_threshold: è©•åˆ†é–¾å€¼ï¼ˆå¯é¸ï¼Œå¦‚æœè¨­ç½®å‰‡ä½¿ç”¨è©•åˆ†é–¾å€¼è€Œé Top-Nï¼‰
            verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
        """
        self.fp_ratio_threshold = fp_ratio_threshold
        self.normal_ratio_threshold = normal_ratio_threshold
        self.attack_ratio_threshold = attack_ratio_threshold
        self.anomaly_score_threshold = anomaly_score_threshold
        self.use_scoring_method = use_scoring_method
        self.top_n_combos = top_n_combos
        self.min_combo_samples = min_combo_samples
        self.score_threshold = score_threshold
        self.verbose = verbose
    
    def analyze_fp_patterns(
        self,
        features_df: pd.DataFrame,
        y_pred: np.ndarray,
        y_true: np.ndarray,
        anomaly_scores: Optional[np.ndarray] = None,
        cleaned_df: Optional[pd.DataFrame] = None,
        train_idx: Optional[pd.Index] = None
    ) -> List[Tuple[str, dict, float, float, float]]:
        """
        åˆ†æ False Positives æ¨¡å¼ï¼Œæ­¸ç´ç™½åå–®è¦å‰‡
        
        å¯ç¨ç«‹ä½¿ç”¨ï¼Œåªéœ€æä¾› DataFrame å’Œé æ¸¬çµæœã€‚
        
        Args:
            features_df: ç‰¹å¾µ DataFrameï¼ˆå¿…é ˆåŒ…å« Proto, Dport ç­‰æ¬„ä½ï¼‰
            y_pred: é æ¸¬çµæœï¼ˆ1=ç•°å¸¸, 0=æ­£å¸¸ï¼‰
            y_true: çœŸå¯¦æ¨™ç±¤ï¼ˆ1=ç•°å¸¸, 0=æ­£å¸¸ï¼‰
            anomaly_scores: ç•°å¸¸åˆ†æ•¸ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ›´ç²¾ç¢ºçš„åˆ†æï¼‰
            cleaned_df: æ¸…æ´—å¾Œçš„åŸå§‹ DataFrameï¼ˆå¯é¸ï¼Œç”¨æ–¼ç²å–ç¼ºå¤±æ¬„ä½ï¼‰
            train_idx: è¨“ç·´é›†ç´¢å¼•ï¼ˆå¯é¸ï¼Œç”¨æ–¼å¾ cleaned_df ç²å–è³‡æ–™ï¼‰
        
        Returns:
            ç™½åå–®è¦å‰‡åˆ—è¡¨ï¼Œæ¯å€‹è¦å‰‡ç‚ºï¼š
            (è¦å‰‡åç¨±, è¦å‰‡åƒæ•¸å­—å…¸, FPä½”æ¯”, æ­£å¸¸æµé‡ä½”æ¯”, æ”»æ“Šè€…ä½”æ¯”)
        """
        # é©—è­‰è¼¸å…¥
        self._validate_inputs(features_df, y_pred, y_true)
        
        # è­˜åˆ¥ False Positives
        fp_mask = (y_pred == 1) & (y_true == 0)
        num_fp = fp_mask.sum()
        
        if num_fp == 0:
            if self.verbose:
                print("   âš ï¸  æ²’æœ‰ False Positivesï¼Œç„¡æ³•æ­¸ç´è¦å‰‡")
            return []
        
        if self.verbose:
            print(f"   ğŸ“Š False Positivesï¼š{num_fp:,} ç­†")
        
        # ç²å–åŸå§‹è³‡è¨Š
        original_info = features_df.copy()
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½ï¼Œå¦‚æœç¼ºå°‘å‰‡å¾ cleaned_df å–å¾—
        required_cols = ['Proto', 'DstAddr', 'Dport', 'SrcAddr']
        missing_cols = [col for col in required_cols if col not in original_info.columns]
        
        if missing_cols and cleaned_df is not None and train_idx is not None:
            cleaned_train = cleaned_df.loc[train_idx]
            for col in missing_cols:
                if col in cleaned_train.columns:
                    original_info[col] = cleaned_train[col]
                    if self.verbose:
                        print(f"      âœ… å¾ cleaned_df å–å¾— {col}")
        
        # åˆ†æ FP çš„æ¨¡å¼
        fp_df = original_info[fp_mask].copy()
        normal_mask = (y_true == 0)
        normal_df = original_info[normal_mask].copy()
        attack_mask = (y_true == 1)
        attack_df = original_info[attack_mask].copy() if len(original_info[attack_mask]) > 0 else pd.DataFrame()
        
        # ğŸ”§ æ–°å¢ï¼šè­˜åˆ¥ False Negativesï¼ˆç”¨æ–¼é›™å‘é©—è­‰ï¼‰
        fn_mask = (y_pred == 0) & (y_true == 1)
        fn_df = original_info[fn_mask].copy() if fn_mask.sum() > 0 else pd.DataFrame()
        num_fn = fn_mask.sum()
        
        if self.verbose and num_fn > 0:
            print(f"   ğŸ“Š False Negativesï¼š{num_fn:,} ç­†ï¼ˆç”¨æ–¼é›™å‘é©—è­‰ï¼‰")
        
        if self.verbose:
            print(f"\n   ğŸ“ˆ False Positive æ¨¡å¼åˆ†æï¼š")
            
            # 1. å”è­°åˆ†å¸ƒ
            if 'Proto' in fp_df.columns:
                proto_counts = fp_df['Proto'].value_counts()
                print(f"      - å”è­°åˆ†å¸ƒï¼š")
                for proto, count in proto_counts.head(5).items():
                    pct = count / num_fp * 100
                    print(f"        {proto}: {count:,} ({pct:.1f}%)")
            
            # 2. ç«¯å£åˆ†å¸ƒ
            if 'Dport' in fp_df.columns:
                port_counts = fp_df['Dport'].value_counts()
                print(f"      - å¸¸è¦‹ç«¯å£ï¼ˆTop 10ï¼‰ï¼š")
                for port, count in port_counts.head(10).items():
                    pct = count / num_fp * 100
                    print(f"        Port {port}: {count:,} ({pct:.1f}%)")
            
            # 3. å”è­°+ç«¯å£çµ„åˆ
            if 'Proto' in fp_df.columns and 'Dport' in fp_df.columns:
                proto_port_counts = fp_df.groupby(['Proto', 'Dport']).size().sort_values(ascending=False)
                print(f"      - å”è­°+ç«¯å£çµ„åˆï¼ˆTop 10ï¼‰ï¼š")
                for (proto, port), count in proto_port_counts.head(10).items():
                    pct = count / num_fp * 100
                    print(f"        {proto.upper()}/{port}: {count:,} ({pct:.1f}%)")
        
        # å®šç¾©å¯ç”¨æ–¼å€åˆ†æ­£å¸¸å’Œæ”»æ“Šçš„è¡Œç‚ºç‰¹å¾µ
        behavioral_features = [
            'TotBytes', 'TotPkts', 'SrcBytes', 'DstBytes', 'Dur',
            'flow_ratio', 'bytes_symmetry', 'packet_size', 
            'bytes_per_second', 'packets_per_second',
            'unique_dst_per_minute_by_src', 'unique_dport_per_minute_by_src',
            'flows_per_minute_by_src', 'total_bytes_per_minute_by_src'
        ]
        
        # æª¢æŸ¥å“ªäº›è¡Œç‚ºç‰¹å¾µå¯ç”¨
        available_behavioral_features = []
        for feat in behavioral_features:
            if feat in original_info.columns:
                available_behavioral_features.append(feat)
            elif f'log_{feat}' in original_info.columns:
                available_behavioral_features.append(f'log_{feat}')
        
        if self.verbose:
            print(f"   ğŸ“Š å¯ç”¨æ–¼è¡Œç‚ºåˆ†æçš„ç‰¹å¾µï¼š{len(available_behavioral_features)} å€‹")
            print(f"\n   ğŸ” æ­¸ç´ç™½åå–®è¦å‰‡ï¼ˆæª¢æŸ¥æ”»æ“Šè€…æ¯”ä¾‹ + è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼‰...")
        
        whitelist_rules = []
        
        # è¦å‰‡ 1: é«˜é »å”è­°+ç«¯å£çµ„åˆ
        if 'Proto' in fp_df.columns and 'Dport' in fp_df.columns:
            proto_port_counts = fp_df.groupby(['Proto', 'Dport']).size().sort_values(ascending=False)
            proto_port_fp_ratio = proto_port_counts / num_fp
            
            if self.use_scoring_method:
                # ğŸ”§ æ–¹æ³• 2ï¼šä½¿ç”¨ç¶œåˆè©•åˆ† + Top-N æˆ–è©•åˆ†é–¾å€¼
                if self.verbose:
                    print(f"   ğŸ“Š ä½¿ç”¨è©•åˆ†æ–¹æ³•åˆ†æå”è­°+ç«¯å£çµ„åˆ...")
                
                # è¨ˆç®—æ¯å€‹çµ„åˆçš„ç¶œåˆé‡è¦æ€§è©•åˆ†
                combo_scores = []
                for (proto, port), fp_count in proto_port_counts.items():
                    port_float = float(port)
                    proto_lower = proto.lower()
                    fp_ratio = proto_port_fp_ratio[(proto, port)]
                    
                    # æª¢æŸ¥åœ¨æ­£å¸¸å’Œæ”»æ“Šæµé‡ä¸­çš„æ¯”ä¾‹
                    normal_combo_count = ((normal_df['Proto'].str.lower() == proto_lower) & 
                                         (normal_df['Dport'].astype(float) == port_float)).sum()
                    normal_combo_ratio = normal_combo_count / len(normal_df) if len(normal_df) > 0 else 0.0
                    
                    attack_combo_count = 0
                    attack_combo_ratio = 0.0
                    if len(attack_df) > 0 and 'Proto' in attack_df.columns and 'Dport' in attack_df.columns:
                        attack_combo_count = ((attack_df['Proto'].str.lower() == proto_lower) & 
                                             (attack_df['Dport'].astype(float) == port_float)).sum()
                        attack_combo_ratio = attack_combo_count / len(attack_df) if len(attack_df) > 0 else 0.0
                    
                    # è¨ˆç®—ç¶œåˆé‡è¦æ€§è©•åˆ†
                    importance_score = self._calculate_combo_importance_score(
                        fp_ratio=fp_ratio,
                        normal_ratio=normal_combo_ratio,
                        attack_ratio=attack_combo_ratio,
                        fp_count=int(fp_count),
                        normal_count=int(normal_combo_count)
                    )
                    
                    combo_scores.append({
                        'proto': proto,
                        'port': port,
                        'score': importance_score,
                        'fp_ratio': fp_ratio,
                        'normal_ratio': normal_combo_ratio,
                        'attack_ratio': attack_combo_ratio,
                        'fp_count': int(fp_count),
                        'normal_count': int(normal_combo_count)
                    })
                
                # æŒ‰è©•åˆ†æ’åº
                combo_scores_df = pd.DataFrame(combo_scores)
                combo_scores_df = combo_scores_df.sort_values('score', ascending=False)
                
                # é¸æ“‡ Top-N æˆ–è©•åˆ†é–¾å€¼
                if self.score_threshold is not None:
                    # ä½¿ç”¨è©•åˆ†é–¾å€¼
                    top_combos = combo_scores_df[combo_scores_df['score'] > self.score_threshold]
                    if self.verbose:
                        if len(top_combos) > 0:
                            print(f"   ğŸ¯ ä½¿ç”¨è©•åˆ†é–¾å€¼ {self.score_threshold:.3f}ï¼Œé¸ä¸­ {len(top_combos)} å€‹çµ„åˆï¼ˆè©•åˆ†ç¯„åœï¼š{top_combos['score'].min():.3f} - {top_combos['score'].max():.3f}ï¼‰")
                        else:
                            print(f"   âš ï¸  ä½¿ç”¨è©•åˆ†é–¾å€¼ {self.score_threshold:.3f}ï¼Œæ²’æœ‰çµ„åˆç¬¦åˆæ¢ä»¶")
                else:
                    # ä½¿ç”¨ Top-N
                    top_combos = combo_scores_df.head(self.top_n_combos)
                    if self.verbose:
                        if len(top_combos) > 0:
                            print(f"   ğŸ¯ é¸æ“‡ Top {len(top_combos)} å€‹çµ„åˆï¼ˆè©•åˆ†ç¯„åœï¼š{top_combos['score'].min():.3f} - {top_combos['score'].max():.3f}ï¼‰")
                        else:
                            print(f"   âš ï¸  æ²’æœ‰çµ„åˆå¯é¸")
                
                # å°é¸ä¸­çš„çµ„åˆé€²è¡Œè©³ç´°åˆ†æ
                for _, combo_info in top_combos.iterrows():
                    proto = combo_info['proto']
                    port = combo_info['port']
                    ratio = combo_info['fp_ratio']
                    normal_combo_ratio = combo_info['normal_ratio']
                    attack_combo_ratio = combo_info['attack_ratio']
                    score = combo_info['score']
                    
                    port_float = float(port)
                    proto_lower = proto.lower()
                    
                    if self.verbose:
                        print(f"      ğŸ” æª¢æŸ¥ {proto.upper()}/{port}: è©•åˆ†={score:.3f}, FPä½”æ¯”={ratio*100:.1f}%, æ­£å¸¸={normal_combo_ratio*100:.2f}%, æ”»æ“Š={attack_combo_ratio*100:.2f}%")
                    
                    # å¾ŒçºŒè™•ç†é‚è¼¯ï¼ˆç”Ÿæˆè¦å‰‡ã€è¡Œç‚ºç‰¹å¾µåˆ†æã€é›™å‘é©—è­‰ç­‰ï¼‰
                    # ğŸ”§ æ–¹æ¡ˆä¸€ï¼šå®Œå…¨ç§»é™¤æ”»æ“Šè€…ä½”æ¯”é™åˆ¶ï¼Œåªè¦æ­£å¸¸æµé‡ä¸­å¸¸è¦‹å°±å˜—è©¦ç”Ÿæˆè¦å‰‡
                    # è®“é›™å‘é©—è­‰ï¼ˆFN æª¢æŸ¥ï¼‰ä¾†æ±ºå®šæ˜¯å¦å®‰å…¨
                    if normal_combo_ratio > self.normal_ratio_threshold:
                        if self.verbose:
                            print(f"         â†’ æ­£å¸¸æµé‡ä½”æ¯” {normal_combo_ratio*100:.2f}% > {self.normal_ratio_threshold*100:.1f}%ï¼Œå˜—è©¦ç”Ÿæˆè¦å‰‡ï¼ˆæ”»æ“Šè€…ä½”æ¯”: {attack_combo_ratio*100:.2f}%ï¼‰")
                        
                        # å…ˆå˜—è©¦æ·»åŠ è¡Œç‚ºç‰¹å¾µæ¢ä»¶
                        behavioral_conditions = self._analyze_behavioral_differences(
                            normal_df, attack_df, proto_lower, port_float, available_behavioral_features,
                            fn_df=fn_df if len(fn_df) > 0 else None,
                            max_features=5
                        )
                        
                        if behavioral_conditions:
                            # æ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆå¸¶è¡Œç‚ºç‰¹å¾µçš„è¦å‰‡
                            rule_name = f"{proto.upper()}/{port} (è¡Œç‚ºç‰¹å¾µéæ¿¾)"
                            rule_params = {
                                'type': 'proto_port_behavioral',
                                'proto': proto_lower,
                                'port': port_float,
                                'anomaly_score_threshold': self.anomaly_score_threshold,
                                'behavioral_conditions': behavioral_conditions
                            }
                            if self.verbose:
                                print(f"         â†’ æ‰¾åˆ° {len(behavioral_conditions)} å€‹è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆå¸¶è¡Œç‚ºç‰¹å¾µçš„è¦å‰‡")
                        else:
                            # æ²’æ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆç°¡å–®è¦å‰‡
                            rule_name = f"{proto.upper()}/{port}"
                            rule_params = {
                                'type': 'proto_port',
                                'proto': proto_lower,
                                'port': port_float,
                                'anomaly_score_threshold': self.anomaly_score_threshold
                            }
                            if self.verbose:
                                print(f"         â†’ æœªæ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆç°¡å–®è¦å‰‡")
                        
                        # ğŸ”§ é—œéµï¼šåªåšé›™å‘é©—è­‰ï¼ˆFN æª¢æŸ¥ï¼‰ï¼Œè®“é©—è­‰ä¾†æ±ºå®šæ˜¯å¦å®‰å…¨
                        if self._validate_rule_against_attacks(rule_params, original_info, attack_mask, fn_mask):
                            whitelist_rules.append((rule_name, rule_params, ratio, normal_combo_ratio, attack_combo_ratio))
                            if self.verbose:
                                print(f"      âœ… è¦å‰‡ï¼š{rule_name} (FPä½”æ¯”: {ratio*100:.1f}%, æ­£å¸¸: {normal_combo_ratio*100:.1f}%, æ”»æ“Š: {attack_combo_ratio*100:.1f}%)")
                                if behavioral_conditions:
                                    for feat, cond in behavioral_conditions.items():
                                        if 'max' in cond:
                                            print(f"         - {feat} < {cond['max']:.2f}")
                        elif self.verbose:
                            print(f"      âš ï¸  è¦å‰‡ {rule_name} å¯èƒ½èª¤æ®ºçœŸå¯¦æ”»æ“Šï¼Œå·²è·³éï¼ˆé›™å‘é©—è­‰å¤±æ•—ï¼‰")
                    else:
                        # æ­£å¸¸æµé‡ä¸­ä¸å¸¸è¦‹ï¼Œè·³é
                        if self.verbose:
                            print(f"         â†’ è·³éï¼šæ­£å¸¸æµé‡ä½”æ¯” {normal_combo_ratio*100:.2f}% <= {self.normal_ratio_threshold*100:.1f}%")
            
            else:
                # ğŸ”§ æ–¹æ³• 1ï¼šä½¿ç”¨å›ºå®šé–¾å€¼ï¼ˆåŸæœ‰æ–¹æ³•ï¼Œä¿æŒå‘å¾Œå…¼å®¹ï¼‰
                high_freq_combos = proto_port_fp_ratio[proto_port_fp_ratio > self.fp_ratio_threshold]
                
                if self.verbose:
                    print(f"   ğŸ“Š ä½¿ç”¨é–¾å€¼æ–¹æ³•ï¼ˆfp_ratio_threshold={self.fp_ratio_threshold*100:.1f}%ï¼‰ï¼Œæ‰¾åˆ° {len(high_freq_combos)} å€‹çµ„åˆ")
                
                for (proto, port), ratio in high_freq_combos.items():
                    port_float = float(port)
                    proto_lower = proto.lower()
                    
                    # æª¢æŸ¥åœ¨æ­£å¸¸å’Œæ”»æ“Šæµé‡ä¸­çš„æ¯”ä¾‹
                    normal_combo_count = ((normal_df['Proto'].str.lower() == proto_lower) & 
                                         (normal_df['Dport'].astype(float) == port_float)).sum()
                    normal_combo_ratio = normal_combo_count / len(normal_df) if len(normal_df) > 0 else 0.0
                    
                    attack_combo_count = 0
                    attack_combo_ratio = 0.0
                    if len(attack_df) > 0 and 'Proto' in attack_df.columns and 'Dport' in attack_df.columns:
                        attack_combo_count = ((attack_df['Proto'].str.lower() == proto_lower) & 
                                             (attack_df['Dport'].astype(float) == port_float)).sum()
                        attack_combo_ratio = attack_combo_count / len(attack_df) if len(attack_df) > 0 else 0.0
                    
                    # ğŸ”§ èª¿è©¦è¼¸å‡ºï¼šé¡¯ç¤ºæ¯å€‹çµ„åˆçš„è©³ç´°ä¿¡æ¯
                    if self.verbose:
                        print(f"      ğŸ” æª¢æŸ¥ {proto.upper()}/{port}: FPä½”æ¯”={ratio*100:.1f}%, æ­£å¸¸={normal_combo_ratio*100:.2f}%, æ”»æ“Š={attack_combo_ratio*100:.2f}%")
                        print(f"         æ¢ä»¶æª¢æŸ¥: normal_combo_ratio > {self.normal_ratio_threshold*100:.1f}%? {normal_combo_ratio > self.normal_ratio_threshold}")
                        print(f"         æ¢ä»¶æª¢æŸ¥: attack_combo_ratio < {self.attack_ratio_threshold*100:.1f}%? {attack_combo_ratio < self.attack_ratio_threshold}")
                        print(f"         æ¢ä»¶æª¢æŸ¥: attack_combo_ratio < {self.attack_ratio_threshold*2*100:.1f}%? {attack_combo_ratio < self.attack_ratio_threshold * 2}")
                    
                    # ğŸ”§ æ–¹æ¡ˆä¸€ï¼šå®Œå…¨ç§»é™¤æ”»æ“Šè€…ä½”æ¯”é™åˆ¶ï¼Œåªè¦æ­£å¸¸æµé‡ä¸­å¸¸è¦‹å°±å˜—è©¦ç”Ÿæˆè¦å‰‡
                    # è®“é›™å‘é©—è­‰ï¼ˆFN æª¢æŸ¥ï¼‰ä¾†æ±ºå®šæ˜¯å¦å®‰å…¨
                    if normal_combo_ratio > self.normal_ratio_threshold:
                        if self.verbose:
                            print(f"         â†’ æ­£å¸¸æµé‡ä½”æ¯” {normal_combo_ratio*100:.2f}% > {self.normal_ratio_threshold*100:.1f}%ï¼Œå˜—è©¦ç”Ÿæˆè¦å‰‡ï¼ˆæ”»æ“Šè€…ä½”æ¯”: {attack_combo_ratio*100:.2f}%ï¼‰")
                        
                        # å…ˆå˜—è©¦æ·»åŠ è¡Œç‚ºç‰¹å¾µæ¢ä»¶
                        behavioral_conditions = self._analyze_behavioral_differences(
                            normal_df, attack_df, proto_lower, port_float, available_behavioral_features,
                            fn_df=fn_df if len(fn_df) > 0 else None,
                            max_features=5
                        )
                        
                        if behavioral_conditions:
                            # æ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆå¸¶è¡Œç‚ºç‰¹å¾µçš„è¦å‰‡
                            rule_name = f"{proto.upper()}/{port} (è¡Œç‚ºç‰¹å¾µéæ¿¾)"
                            rule_params = {
                                'type': 'proto_port_behavioral',
                                'proto': proto_lower,
                                'port': port_float,
                                'anomaly_score_threshold': self.anomaly_score_threshold,
                                'behavioral_conditions': behavioral_conditions
                            }
                            if self.verbose:
                                print(f"         â†’ æ‰¾åˆ° {len(behavioral_conditions)} å€‹è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆå¸¶è¡Œç‚ºç‰¹å¾µçš„è¦å‰‡")
                        else:
                            # æ²’æ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆç°¡å–®è¦å‰‡
                            rule_name = f"{proto.upper()}/{port}"
                            rule_params = {
                                'type': 'proto_port',
                                'proto': proto_lower,
                                'port': port_float,
                                'anomaly_score_threshold': self.anomaly_score_threshold
                            }
                            if self.verbose:
                                print(f"         â†’ æœªæ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œç”Ÿæˆç°¡å–®è¦å‰‡")
                        
                        # ğŸ”§ é—œéµï¼šåªåšé›™å‘é©—è­‰ï¼ˆFN æª¢æŸ¥ï¼‰ï¼Œè®“é©—è­‰ä¾†æ±ºå®šæ˜¯å¦å®‰å…¨
                        if self._validate_rule_against_attacks(rule_params, original_info, attack_mask, fn_mask):
                            whitelist_rules.append((rule_name, rule_params, ratio, normal_combo_ratio, attack_combo_ratio))
                            if self.verbose:
                                print(f"      âœ… è¦å‰‡ï¼š{rule_name} (FPä½”æ¯”: {ratio*100:.1f}%, æ­£å¸¸: {normal_combo_ratio*100:.1f}%, æ”»æ“Š: {attack_combo_ratio*100:.1f}%)")
                                if behavioral_conditions:
                                    for feat, cond in behavioral_conditions.items():
                                        if 'max' in cond:
                                            print(f"         - {feat} < {cond['max']:.2f}")
                        elif self.verbose:
                            print(f"      âš ï¸  è¦å‰‡ {rule_name} å¯èƒ½èª¤æ®ºçœŸå¯¦æ”»æ“Šï¼Œå·²è·³éï¼ˆé›™å‘é©—è­‰å¤±æ•—ï¼‰")
                    else:
                        # æ­£å¸¸æµé‡ä¸­ä¸å¸¸è¦‹ï¼Œè·³é
                        if self.verbose:
                            print(f"         â†’ è·³éï¼šæ­£å¸¸æµé‡ä½”æ¯” {normal_combo_ratio*100:.2f}% <= {self.normal_ratio_threshold*100:.1f}%")
        
        # è¦å‰‡ 2: å¸¸è¦‹æœå‹™ç«¯å£
        common_service_ports = {
            53: 'DNS',
            123: 'NTP',
            67: 'DHCP',
            68: 'DHCP',
            161: 'SNMP',
            5353: 'mDNS',
            80: 'HTTP',
            443: 'HTTPS',
            22: 'SSH',
            25: 'SMTP'
        }
        
        if 'Dport' in fp_df.columns:
            for port, service_name in common_service_ports.items():
                port_float = float(port)
                port_fp_count = (fp_df['Dport'].astype(float) == port_float).sum()
                port_fp_ratio = port_fp_count / num_fp
                
                if port_fp_ratio > self.fp_ratio_threshold:
                    normal_port_count = (normal_df['Dport'].astype(float) == port_float).sum()
                    normal_port_ratio = normal_port_count / len(normal_df) if len(normal_df) > 0 else 0.0
                    
                    attack_port_count = 0
                    attack_port_ratio = 0.0
                    if len(attack_df) > 0 and 'Dport' in attack_df.columns:
                        attack_port_count = (attack_df['Dport'].astype(float) == port_float).sum()
                        attack_port_ratio = attack_port_count / len(attack_df) if len(attack_df) > 0 else 0.0
                    
                    if normal_port_ratio > self.normal_ratio_threshold and attack_port_ratio < self.attack_ratio_threshold:
                        rule_name = f"{service_name} (Port {port})"
                        rule_params = {
                            'type': 'port',
                            'port': port_float,
                            'anomaly_score_threshold': self.anomaly_score_threshold
                        }
                        # ğŸ”§ ä¿®æ­£ï¼šåœ¨åŠ å…¥å‰é€²è¡Œé©—è­‰
                        if self._validate_rule_against_attacks(rule_params, original_info, attack_mask, fn_mask):
                            whitelist_rules.append((rule_name, rule_params, port_fp_ratio, normal_port_ratio, attack_port_ratio))
                            if self.verbose:
                                print(f"      âœ… è¦å‰‡ï¼š{rule_name} (FPä½”æ¯”: {port_fp_ratio*100:.1f}%, æ­£å¸¸: {normal_port_ratio*100:.1f}%, æ”»æ“Š: {attack_port_ratio*100:.1f}%)")
                        elif self.verbose:
                            print(f"      âš ï¸  è¦å‰‡ {rule_name} å¯èƒ½èª¤æ®ºçœŸå¯¦æ”»æ“Šï¼Œå·²è·³é")
                    elif normal_port_ratio > self.normal_ratio_threshold and attack_port_ratio < self.attack_ratio_threshold * 2:
                        # ğŸ”§ æ”¹é€²ï¼šå°æ–¼æ”»æ“Šè€…ä½”æ¯”ç¨é«˜çš„æƒ…æ³ï¼ˆ< 2å€é–¾å€¼ï¼‰ï¼Œä¹Ÿå˜—è©¦æ·»åŠ è¡Œç‚ºç‰¹å¾µæ¢ä»¶
                        # éœ€è¦å…ˆç²å–å”è­°è³‡è¨Šï¼ˆå¾ FP è³‡æ–™ä¸­ï¼‰
                        if 'Proto' in fp_df.columns:
                            # æ‰¾åˆ°è©²ç«¯å£æœ€å¸¸è¦‹çš„å”è­°
                            port_fp_df = fp_df[fp_df['Dport'].astype(float) == port_float]
                            if len(port_fp_df) > 0:
                                most_common_proto = port_fp_df['Proto'].mode()
                                if len(most_common_proto) > 0:
                                    proto_lower = most_common_proto[0].lower()
                                    behavioral_conditions = self._analyze_behavioral_differences(
                                        normal_df, attack_df, proto_lower, port_float, available_behavioral_features,
                                        fn_df=fn_df if len(fn_df) > 0 else None,
                                        max_features=5  # ğŸ”§ æ”¹é€²ï¼šå…è¨±æœ€å¤š 5 å€‹è¡Œç‚ºç‰¹å¾µæ¢ä»¶
                                    )
                                    
                                    if behavioral_conditions:
                                        rule_name = f"{service_name} (Port {port}, è¡Œç‚ºç‰¹å¾µéæ¿¾)"
                                        rule_params = {
                                            'type': 'port_behavioral',
                                            'port': port_float,
                                            'anomaly_score_threshold': self.anomaly_score_threshold,
                                            'behavioral_conditions': behavioral_conditions
                                        }
                                        # ğŸ”§ æ–°å¢ï¼šé›™å‘é©—è­‰ - æª¢æŸ¥è¦å‰‡æ˜¯å¦æœƒèª¤æ®ºçœŸå¯¦æ”»æ“Š
                                        if self._validate_rule_against_attacks(rule_params, original_info, attack_mask, fn_mask):
                                            whitelist_rules.append((rule_name, rule_params, port_fp_ratio, normal_port_ratio, attack_port_ratio))
                                            if self.verbose:
                                                print(f"      âœ… è¦å‰‡ï¼ˆå«è¡Œç‚ºç‰¹å¾µï¼‰ï¼š{rule_name}")
                                                for feat, cond in behavioral_conditions.items():
                                                    if 'max' in cond:
                                                        print(f"         - {feat} < {cond['max']:.2f}")
                                        elif self.verbose:
                                            print(f"      âš ï¸  è¦å‰‡ {rule_name} å¯èƒ½èª¤æ®ºçœŸå¯¦æ”»æ“Šï¼Œå·²è·³é")
                                    else:
                                        # ğŸ”§ ä¿®æ­£ï¼šå³ä½¿æ²’æœ‰æ‰¾åˆ°è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œå¦‚æœæ”»æ“Šè€…ä½”æ¯”ä»ç„¶è¼ƒä½ï¼ˆ< 1.5å€é–¾å€¼ï¼‰ï¼Œä¹Ÿç”Ÿæˆç°¡å–®è¦å‰‡
                                        if attack_port_ratio < self.attack_ratio_threshold * 1.5:
                                            rule_name = f"{service_name} (Port {port})"
                                            rule_params = {
                                                'type': 'port',
                                                'port': port_float,
                                                'anomaly_score_threshold': self.anomaly_score_threshold
                                            }
                                            # é©—è­‰å¾ŒåŠ å…¥
                                            if self._validate_rule_against_attacks(rule_params, original_info, attack_mask, fn_mask):
                                                whitelist_rules.append((rule_name, rule_params, port_fp_ratio, normal_port_ratio, attack_port_ratio))
                                                if self.verbose:
                                                    print(f"      âœ… è¦å‰‡ï¼ˆæ”»æ“Šè€…ä½”æ¯”ä½ï¼Œç„¡è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼‰ï¼š{rule_name} (FPä½”æ¯”: {port_fp_ratio*100:.1f}%, æ­£å¸¸: {normal_port_ratio*100:.1f}%, æ”»æ“Š: {attack_port_ratio*100:.1f}%)")
                                            elif self.verbose:
                                                print(f"      âš ï¸  è¦å‰‡ {rule_name} å¯èƒ½èª¤æ®ºçœŸå¯¦æ”»æ“Šï¼Œå·²è·³é")
        
        # ğŸ”§ ä¿®æ­£ï¼šè¦å‰‡åœ¨ç”Ÿæˆæ™‚å·²ç¶“é©—è­‰éäº†ï¼Œä¸éœ€è¦é‡è¤‡é©—è­‰
        # ç›´æ¥è¿”å›å·²é©—è­‰çš„è¦å‰‡
        if self.verbose:
            print(f"\n   âœ… æ­¸ç´å‡º {len(whitelist_rules)} å€‹ç™½åå–®è¦å‰‡ï¼ˆç¶“éé›™å‘é©—è­‰ï¼‰")
        
        return whitelist_rules
    
    def _validate_inputs(
        self,
        features_df: pd.DataFrame,
        y_pred: np.ndarray,
        y_true: np.ndarray
    ):
        """é©—è­‰è¼¸å…¥è³‡æ–™æ ¼å¼"""
        required_cols = ['Proto', 'Dport']
        missing_cols = [col for col in required_cols if col not in features_df.columns]
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_cols}")
        
        if len(y_pred) != len(features_df):
            raise ValueError(f"y_pred é•·åº¦ ({len(y_pred)}) èˆ‡ features_df é•·åº¦ ({len(features_df)}) ä¸ä¸€è‡´")
        
        if len(y_true) != len(features_df):
            raise ValueError(f"y_true é•·åº¦ ({len(y_true)}) èˆ‡ features_df é•·åº¦ ({len(features_df)}) ä¸ä¸€è‡´")
    
    def _analyze_behavioral_differences(
        self,
        normal_df: pd.DataFrame,
        attack_df: pd.DataFrame,
        proto: str,
        port: float,
        available_features: List[str],
        fn_df: Optional[pd.DataFrame] = None,
        max_features: int = 5
    ) -> Dict[str, Dict[str, float]]:
        """
        åˆ†ææ­£å¸¸å’Œæ”»æ“Šæµé‡çš„è¡Œç‚ºç‰¹å¾µå·®ç•°
        
        ä½¿ç”¨æ­£å¸¸æµé‡çš„çœ¾æ•¸ä½œç‚ºå…¸å‹å€¼ï¼Œä¸¦ç´å…¥æ”»æ“Šæµé‡çš„ P10 ä¾†é¿å…èª¤æ®ºçœŸå¯¦æ”»æ“Šã€‚
        
        Args:
            max_features: æœ€å¤šæ·»åŠ çš„è¡Œç‚ºç‰¹å¾µæ¢ä»¶æ•¸é‡ï¼ˆé è¨­ 5ï¼‰
        """
        behavioral_conditions = {}
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨ï¼ˆé˜²ç¦¦æ€§ç·¨ç¨‹ï¼‰
        # ç•¶ attack_df æ˜¯ç©ºçš„ DataFrameï¼ˆæ²’æœ‰åˆ—ï¼‰æ™‚ï¼Œéœ€è¦æå‰è¿”å›
        required_cols = ['Proto', 'Dport']
        if len(normal_df) == 0 or not all(col in normal_df.columns for col in required_cols):
            return behavioral_conditions
        if len(attack_df) == 0 or not all(col in attack_df.columns for col in required_cols):
            return behavioral_conditions
        
        # æå–è©²å”è­°+ç«¯å£çµ„åˆçš„æ­£å¸¸å’Œæ”»æ“Šæµé‡
        normal_mask = ((normal_df['Proto'].str.lower() == proto) & 
                      (normal_df['Dport'].astype(float) == port))
        attack_mask = ((attack_df['Proto'].str.lower() == proto) & 
                      (attack_df['Dport'].astype(float) == port))
        
        normal_flows = normal_df[normal_mask] if normal_mask.sum() > 0 else pd.DataFrame()
        attack_flows = attack_df[attack_mask] if attack_mask.sum() > 0 else pd.DataFrame()
        
        # å¦‚æœæœ‰ FN è³‡æ–™ï¼Œä¹Ÿæå–
        fn_flows = pd.DataFrame()
        if fn_df is not None and len(fn_df) > 0 and all(col in fn_df.columns for col in required_cols):
            fn_mask = ((fn_df['Proto'].str.lower() == proto) & 
                      (fn_df['Dport'].astype(float) == port))
            fn_flows = fn_df[fn_mask] if fn_mask.sum() > 0 else pd.DataFrame()
        
        if len(normal_flows) == 0 or len(attack_flows) == 0:
            return behavioral_conditions
        
        for feat in available_features:
            if feat in normal_flows.columns and feat in attack_flows.columns:
                normal_values = normal_flows[feat].dropna()
                attack_values = attack_flows[feat].dropna()
                
                if len(normal_values) > 10 and len(attack_values) > 10:
                    # æ­£å¸¸æµé‡çš„çµ±è¨ˆå€¼
                    normal_p75 = normal_values.quantile(0.75)
                    normal_p95 = normal_values.quantile(0.95)  # ä¿æŒ P95 æ¨™æº–
                    # è¨ˆç®—çœ¾æ•¸ï¼ˆæœ€å¸¸è¦‹çš„å€¼ï¼‰
                    normal_mode = normal_values.mode()
                    normal_mode_value = normal_mode[0] if len(normal_mode) > 0 else normal_p75
                    
                    # æ”»æ“Šæµé‡çš„çµ±è¨ˆå€¼ï¼ˆä½¿ç”¨æ›´ä¿å®ˆçš„ P5 è€Œé P10ï¼‰
                    attack_p5 = attack_values.quantile(0.05)  # æ”»æ“Šçš„æœ€å°å€¼ï¼ˆP5ï¼Œæ›´ä¿å®ˆï¼‰
                    attack_p10 = attack_values.quantile(0.10)  # ä¿ç•™ P10 ä½œç‚ºå‚™ç”¨
                    attack_p50 = attack_values.quantile(0.50)
                    
                    # å¦‚æœæœ‰ FN è³‡æ–™ï¼Œä¹Ÿè¨ˆç®—
                    fn_p5 = None
                    fn_p10 = None
                    if len(fn_flows) > 0 and feat in fn_flows.columns:
                        fn_values = fn_flows[feat].dropna()
                        if len(fn_values) > 5:
                            fn_p5 = fn_values.quantile(0.05)  # FN çš„ P5
                            fn_p10 = fn_values.quantile(0.10)
                    
                    # ğŸ”§ æ”¹é€²ï¼šä½¿ç”¨å¤šç¨®æ¢ä»¶ä¾†æª¢æ¸¬è¡Œç‚ºç‰¹å¾µå·®ç•°ï¼Œæ›´å®¹æ˜“æ‰¾åˆ°å·®ç•°
                    # æ¢ä»¶ 1ï¼šæ”»æ“Šçš„ä¸­ä½æ•¸æ˜é¡¯é«˜æ–¼æ­£å¸¸çš„ P75ï¼ˆæ”¾å¯¬åˆ° 1.2 å€ï¼‰
                    condition_1 = attack_p50 > normal_p75 * 1.2
                    # æ¢ä»¶ 2ï¼šæ”»æ“Šçš„ 25% åˆ†ä½æ•¸é«˜æ–¼æ­£å¸¸çš„ 90% åˆ†ä½æ•¸
                    attack_p25 = attack_values.quantile(0.25)
                    normal_p90 = normal_values.quantile(0.90)
                    condition_2 = attack_p25 > normal_p90
                    # æ¢ä»¶ 3ï¼šæ”»æ“Šçš„ 10% åˆ†ä½æ•¸é«˜æ–¼æ­£å¸¸çš„ 95% åˆ†ä½æ•¸
                    condition_3 = attack_p10 > normal_p95
                    
                    # å¦‚æœæ»¿è¶³ä»»ä¸€æ¢ä»¶ï¼Œä¸”å°šæœªé”åˆ°æœ€å¤§ç‰¹å¾µæ•¸é‡
                    if (condition_1 or condition_2 or condition_3) and len(behavioral_conditions) < max_features:
                        # ä½¿ç”¨æ›´ä¿å®ˆçš„é–¾å€¼ï¼šå„ªå…ˆä½¿ç”¨ attack_p5ï¼ˆæ›´åš´æ ¼ï¼‰
                        # ç¢ºä¿ä¸æœƒèª¤æ®ºæ”»æ“Šæµé‡
                        if attack_p5 > 0 and not np.isnan(attack_p5):
                            max_threshold = min(normal_p95, attack_p5)
                        else:
                            max_threshold = normal_p95
                        
                        
                        # å¦‚æœæœ‰ FN è³‡æ–™ï¼Œé€²ä¸€æ­¥æ”¶ç·Šï¼ˆä½¿ç”¨ FN çš„ P5 ä½œç‚ºåƒè€ƒï¼‰
                        if fn_p5 is not None and fn_p5 < max_threshold:
                            max_threshold = min(max_threshold, fn_p5 * 0.9)  # å†ä¿å®ˆ 10%
                        elif fn_p10 is not None and fn_p10 < max_threshold:
                            max_threshold = min(max_threshold, fn_p10 * 0.9)  # å†ä¿å®ˆ 10%
                        
                        # ç¢ºä¿é–¾å€¼æœ‰æ„ç¾©ï¼ˆä¸èƒ½å°æ–¼æ­£å¸¸æµé‡çš„çœ¾æ•¸ï¼‰
                        if max_threshold > normal_mode_value:
                            behavioral_conditions[feat] = {'max': float(max_threshold)}
                            if self.verbose:
                                condition_desc = []
                                if condition_1:
                                    condition_desc.append("ä¸­ä½æ•¸>P75Ã—1.2")
                                if condition_2:
                                    condition_desc.append("P25>P90")
                                if condition_3:
                                    condition_desc.append("P10>P95")
                                
                                info_parts = [
                                    f"æ¢ä»¶: {', '.join(condition_desc)}",
                                    f"æ­£å¸¸çœ¾æ•¸: {normal_mode_value:.2f}",
                                    f"æ­£å¸¸ P95: {normal_p95:.2f}",
                                    f"æ”»æ“Š P5: {attack_p5:.2f}",
                                    f"æ”»æ“Š P10: {attack_p10:.2f}",
                                    f"æ”»æ“Šä¸­ä½æ•¸: {attack_p50:.2f}"
                                ]
                                if fn_p5 is not None:
                                    info_parts.append(f"FN P5: {fn_p5:.2f}")
                                elif fn_p10 is not None:
                                    info_parts.append(f"FN P10: {fn_p10:.2f}")
                                info_parts.append(f"ä½¿ç”¨é–¾å€¼: {max_threshold:.2f}")
                                print(f"         ğŸ’¡ ç™¼ç¾å·®ç•°ï¼š{feat} ({', '.join(info_parts)})")
        
        return behavioral_conditions
    
    def _calculate_combo_importance_score(
        self,
        fp_ratio: float,
        normal_ratio: float,
        attack_ratio: float,
        fp_count: int,
        normal_count: int
    ) -> float:
        """
        è¨ˆç®—å”è­°+ç«¯å£çµ„åˆçš„é‡è¦æ€§è©•åˆ†
        
        ç¶œåˆè€ƒæ…®ï¼š
        1. FP ä½”æ¯”ï¼ˆè¶Šé«˜è¶Šé‡è¦ï¼‰
        2. æ­£å¸¸æµé‡ä½”æ¯”ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œè¡¨ç¤ºæ˜¯å¸¸è¦‹çš„æ­£å¸¸æµé‡ï¼‰
        3. æ”»æ“Šæµé‡ä½”æ¯”ï¼ˆè¶Šä½è¶Šå¥½ï¼Œè¡¨ç¤ºä¸æ˜¯æ”»æ“Šï¼‰
        4. çµ•å°æ•¸é‡ï¼ˆç¢ºä¿çµ±è¨ˆå¯é æ€§ï¼‰
        
        Args:
            fp_ratio: FP ä¸­è©²çµ„åˆçš„ä½”æ¯”
            normal_ratio: æ­£å¸¸æµé‡ä¸­è©²çµ„åˆçš„ä½”æ¯”
            attack_ratio: æ”»æ“Šæµé‡ä¸­è©²çµ„åˆçš„ä½”æ¯”
            fp_count: FP ä¸­è©²çµ„åˆçš„çµ•å°æ•¸é‡
            normal_count: æ­£å¸¸æµé‡ä¸­è©²çµ„åˆçš„çµ•å°æ•¸é‡
        
        Returns:
            é‡è¦æ€§è©•åˆ†ï¼ˆ0-1 ä¹‹é–“ï¼Œè¶Šé«˜è¶Šé‡è¦ï¼‰
        """
        # 1. æ¨£æœ¬é‡æª¢æŸ¥ï¼šå¦‚æœæ¨£æœ¬å¤ªå°‘ï¼Œé™ä½è©•åˆ†
        sample_penalty = 1.0
        if fp_count < self.min_combo_samples:
            sample_penalty = fp_count / self.min_combo_samples  # ç·šæ€§æ‡²ç½°
        
        # 2. FP ä½”æ¯”ï¼ˆæ¬Šé‡ 0.4ï¼‰ï¼šè¶Šé«˜è¶Šå¥½
        fp_score = min(fp_ratio * 10, 1.0)  # å‡è¨­ 10% ä»¥ä¸Šç‚ºæ»¿åˆ†
        
        # 3. æ­£å¸¸æµé‡ä½”æ¯”ï¼ˆæ¬Šé‡ 0.3ï¼‰ï¼šè¶Šé«˜è¶Šå¥½ï¼Œè¡¨ç¤ºæ˜¯å¸¸è¦‹çš„æ­£å¸¸æµé‡
        normal_score = min(normal_ratio * 20, 1.0)  # å‡è¨­ 5% ä»¥ä¸Šç‚ºæ»¿åˆ†
        
        # 4. æ”»æ“Šæµé‡ä½”æ¯”ï¼ˆæ¬Šé‡ 0.3ï¼‰ï¼šè¶Šä½è¶Šå¥½ï¼ˆåå‘è©•åˆ†ï¼‰
        attack_score = max(0, 1.0 - attack_ratio * 10)  # å‡è¨­ 10% ä»¥ä¸‹ç‚ºæ»¿åˆ†
        
        # 5. ç¶œåˆè©•åˆ†ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
        importance_score = (
            fp_score * 0.4 +
            normal_score * 0.3 +
            attack_score * 0.3
        ) * sample_penalty
        
        return importance_score
    
    def _validate_rule_against_attacks(
        self,
        rule_params: dict,
        original_info: pd.DataFrame,
        attack_mask: np.ndarray,
        fn_mask: np.ndarray
    ) -> bool:
        """
        é›™å‘é©—è­‰è¦å‰‡ï¼šæª¢æŸ¥è¦å‰‡æ˜¯å¦æœƒèª¤æ®ºçœŸå¯¦æ”»æ“Š
        
        ğŸ”§ æ–¹æ¡ˆä¸€ï¼šåªæª¢æŸ¥ FNï¼Œä¸æª¢æŸ¥æ”»æ“Šæµé‡ï¼ˆè®“è¦å‰‡èƒ½ç”Ÿæˆï¼Œå†æ ¹æ“šçµæœèª¿æ•´ç­–ç•¥ï¼‰
        
        Args:
            rule_params: è¦å‰‡åƒæ•¸å­—å…¸
            original_info: åŸå§‹ç‰¹å¾µ DataFrame
            attack_mask: æ”»æ“Šæµé‡çš„é®ç½©
            fn_mask: False Negatives çš„é®ç½©
        
        Returns:
            True å¦‚æœè¦å‰‡å®‰å…¨ï¼ˆä¸æœƒèª¤æ®ºå¤ªå¤šæ”»æ“Šï¼‰ï¼ŒFalse å¦å‰‡
        """
        # å‰µå»ºè¦å‰‡é®ç½©
        rule_mask = self._create_rule_mask_for_validation(rule_params, original_info)
        
        if rule_mask.sum() == 0:
            return True  # å¦‚æœè¦å‰‡ä¸åŒ¹é…ä»»ä½•æµé‡ï¼Œè¦–ç‚ºå®‰å…¨
        
        # ğŸ”§ æ–¹æ¡ˆä¸€ï¼šåªæª¢æŸ¥ FNï¼Œä¸æª¢æŸ¥æ”»æ“Šæµé‡
        # æª¢æŸ¥è©²è¦å‰‡åŒ¹é…çš„ FN æµé‡ï¼ˆé€™äº›æ˜¯å·²ç¶“è¢«èª¤åˆ¤ç‚ºæ­£å¸¸çš„æ”»æ“Šï¼‰
        matched_fn = (rule_mask & fn_mask).sum() if fn_mask.sum() > 0 else 0
        total_fn = fn_mask.sum() if fn_mask.sum() > 0 else 0
        
        # åªæª¢æŸ¥ FNï¼šå¦‚æœåŒ¹é…è¶…é 5% çš„ FNï¼Œè¦–ç‚ºä¸å®‰å…¨
        if total_fn > 0:
            fn_ratio = matched_fn / total_fn
            if fn_ratio > 0.10:
                if self.verbose:
                    print(f"         âš ï¸  è¦å‰‡åŒ¹é… {fn_ratio*100:.2f}% çš„ FN æµé‡ ({matched_fn:,}/{total_fn:,})")
                return False
        
        # ğŸ”§ æš«æ™‚ç§»é™¤æ”»æ“Šæµé‡æª¢æŸ¥ï¼Œè®“è¦å‰‡èƒ½ç”Ÿæˆ
        # å¾ŒçºŒå¯ä»¥æ ¹æ“šå¯¦éš›æ•ˆæœå†èª¿æ•´ç­–ç•¥
        # if total_attacks > 0:
        #     attack_ratio = matched_attacks / total_attacks
        #     if attack_ratio > 0.01:
        #         if self.verbose:
        #             print(f"         âš ï¸  è¦å‰‡å¯èƒ½èª¤æ®º {attack_ratio*100:.2f}% çš„æ”»æ“Šæµé‡ ({matched_attacks:,}/{total_attacks:,})")
        #         return False
        
        return True
    
    def _create_rule_mask_for_validation(
        self,
        rule_params: dict,
        original_info: pd.DataFrame
    ) -> np.ndarray:
        """
        ç‚ºé©—è­‰å‰µå»ºè¦å‰‡é®ç½©ï¼ˆé¡ä¼¼ _create_rule_maskï¼Œä½†ç”¨æ–¼é©—è­‰éšæ®µï¼‰
        
        Args:
            rule_params: è¦å‰‡åƒæ•¸å­—å…¸
            original_info: ç‰¹å¾µ DataFrame
        
        Returns:
            å¸ƒæ—é®ç½©é™£åˆ—
        """
        rule_type = rule_params.get('type')
        
        if rule_type == 'proto_port' or rule_type == 'proto_port_behavioral':
            proto = rule_params.get('proto')
            port = rule_params.get('port')
            if 'Proto' in original_info.columns and 'Dport' in original_info.columns:
                rule_mask = (
                    (original_info['Proto'].str.lower() == proto).values & 
                    (original_info['Dport'].astype(float) == port).values
                )
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        elif rule_type == 'port' or rule_type == 'port_behavioral':
            port = rule_params.get('port')
            if 'Dport' in original_info.columns:
                rule_mask = (original_info['Dport'].astype(float) == port).values
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        else:
            # å…¶ä»–è¦å‰‡é¡å‹æš«æ™‚ä¸è™•ç†
            rule_mask = np.zeros(len(original_info), dtype=bool)
        
        # å¦‚æœæœ‰è¡Œç‚ºç‰¹å¾µæ¢ä»¶ï¼Œä¹Ÿæ‡‰ç”¨
        behavioral_conditions = rule_params.get('behavioral_conditions', {})
        if behavioral_conditions:
            for feat, cond in behavioral_conditions.items():
                feat_name = None
                if feat in original_info.columns:
                    feat_name = feat
                elif f'log_{feat}' in original_info.columns:
                    feat_name = f'log_{feat}'
                
                if feat_name:
                    feat_values = original_info[feat_name].values
                    if 'max' in cond:
                        feat_mask = (feat_values < cond['max']) | np.isnan(feat_values)
                        rule_mask = rule_mask & feat_mask
                    elif 'min' in cond:
                        feat_mask = (feat_values > cond['min']) | np.isnan(feat_values)
                        rule_mask = rule_mask & feat_mask
        
        return rule_mask
    
    def get_statistics(
        self,
        features_df: pd.DataFrame,
        y_pred: np.ndarray,
        y_true: np.ndarray,
        whitelist_rules: List[Tuple[str, dict, float, float, float]]
    ) -> Dict[str, Any]:
        """
        ç²å–ç™½åå–®è¦å‰‡çš„çµ±è¨ˆåˆ†æ
        
        å¯ç¨ç«‹ä½¿ç”¨ï¼Œç”¨æ–¼åˆ†æè¦å‰‡çš„æ•ˆæœã€‚
        
        Args:
            features_df: ç‰¹å¾µ DataFrame
            y_pred: é æ¸¬çµæœ
            y_true: çœŸå¯¦æ¨™ç±¤
            whitelist_rules: ç™½åå–®è¦å‰‡åˆ—è¡¨
        
        Returns:
            çµ±è¨ˆå­—å…¸ï¼ŒåŒ…å«ï¼š
            - total_rules: è¦å‰‡ç¸½æ•¸
            - rules_by_type: æŒ‰é¡å‹åˆ†çµ„çš„è¦å‰‡æ•¸é‡
            - estimated_fp_reduction: ä¼°è¨ˆçš„ FP æ¸›å°‘æ•¸é‡
            - coverage: è¦å‰‡è¦†è“‹çš„æµé‡æ¯”ä¾‹
        """
        stats = {
            'total_rules': len(whitelist_rules),
            'rules_by_type': {},
            'estimated_fp_reduction': 0,
            'coverage': 0.0
        }
        
        # çµ±è¨ˆè¦å‰‡é¡å‹
        for rule_name, rule_params, fp_ratio, normal_ratio, attack_ratio in whitelist_rules:
            rule_type = rule_params.get('type', 'unknown')
            stats['rules_by_type'][rule_type] = stats['rules_by_type'].get(rule_type, 0) + 1
        
        # è¨ˆç®—ä¼°è¨ˆçš„ FP æ¸›å°‘ï¼ˆåŸºæ–¼ FP ä½”æ¯”ï¼‰
        total_fp = ((y_pred == 1) & (y_true == 0)).sum()
        estimated_reduction = sum(fp_ratio * total_fp for _, _, fp_ratio, _, _ in whitelist_rules)
        stats['estimated_fp_reduction'] = int(estimated_reduction)
        
        return stats
    
    def save_rules(
        self,
        rules: List[Tuple[str, dict, float, float, float]],
        filepath: Union[str, Path]
    ):
        """
        ä¿å­˜ç™½åå–®è¦å‰‡åˆ° JSON æª”æ¡ˆ
        
        å¯ç¨ç«‹ä½¿ç”¨ï¼Œæ–¹ä¾¿è¦å‰‡çš„ä¿å­˜å’Œåˆ†äº«ã€‚
        
        Args:
            rules: ç™½åå–®è¦å‰‡åˆ—è¡¨
            filepath: ä¿å­˜è·¯å¾‘ï¼ˆ.json æª”æ¡ˆï¼‰
        
        ç¯„ä¾‹ï¼š
            >>> rules = [("TCP/80", {'type': 'proto_port', 'proto': 'tcp', 'port': 80.0}, 0.1, 0.05, 0.01)]
            >>> analyzer = WhitelistAnalyzer(verbose=False)
            >>> analyzer.save_rules(rules, 'data/models/whitelist_rules/my_rules.json')
        """
        filepath = Path(filepath)
        if not filepath.suffix == '.json':
            filepath = filepath.with_suffix('.json')
        
        # è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_rules = []
        for rule_name, rule_params, fp_ratio, normal_ratio, attack_ratio in rules:
            serializable_rules.append({
                'name': rule_name,
                'params': rule_params,
                'fp_ratio': float(fp_ratio),
                'normal_ratio': float(normal_ratio),
                'attack_ratio': float(attack_ratio)
            })
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_rules, f, indent=2, ensure_ascii=False)
        
        if self.verbose:
            print(f"   ğŸ’¾ å·²ä¿å­˜ {len(rules)} å€‹è¦å‰‡åˆ° {filepath}")
    
    def load_rules(
        self,
        filepath: Union[str, Path]
    ) -> List[Tuple[str, dict, float, float, float]]:
        """
        å¾ JSON æª”æ¡ˆè¼‰å…¥ç™½åå–®è¦å‰‡
        
        å¯ç¨ç«‹ä½¿ç”¨ï¼Œæ–¹ä¾¿è¦å‰‡çš„è¼‰å…¥å’Œé‡ç”¨ã€‚
        
        Args:
            filepath: JSON æª”æ¡ˆè·¯å¾‘
        
        Returns:
            ç™½åå–®è¦å‰‡åˆ—è¡¨
        
        ç¯„ä¾‹ï¼š
            >>> analyzer = WhitelistAnalyzer(verbose=False)
            >>> rules = analyzer.load_rules('data/models/whitelist_rules/my_rules.json')
        """
        filepath = Path(filepath)
        if not filepath.exists():
            raise FileNotFoundError(f"è¦å‰‡æª”æ¡ˆä¸å­˜åœ¨ï¼š{filepath}")
        
        with open(filepath, 'r', encoding='utf-8') as f:
            serializable_rules = json.load(f)
        
        # è½‰æ›å›åŸå§‹æ ¼å¼
        rules = []
        for rule_data in serializable_rules:
            rules.append((
                rule_data['name'],
                rule_data['params'],
                rule_data['fp_ratio'],
                rule_data['normal_ratio'],
                rule_data['attack_ratio']
            ))
        
        if self.verbose:
            print(f"   ğŸ“‚ å·²è¼‰å…¥ {len(rules)} å€‹è¦å‰‡å¾ {filepath}")
        
        return rules
    
    @staticmethod
    def is_private_ip(ip_str: str) -> bool:
        """
        åˆ¤æ–·æ˜¯å¦ç‚ºå…§ç¶² IPï¼ˆéœæ…‹æ–¹æ³•ï¼Œå¯ç¨ç«‹ä½¿ç”¨ï¼‰
        
        >>> WhitelistAnalyzer.is_private_ip('192.168.1.1')
        True
        >>> WhitelistAnalyzer.is_private_ip('8.8.8.8')
        False
        """
        try:
            ip = ipaddress.ip_address(str(ip_str))
            return ip.is_private or ip.is_loopback or ip.is_link_local
        except:
            return False


class WhitelistApplier:
    """
    ç™½åå–®è¦å‰‡æ‡‰ç”¨å™¨
    
    å°‡ç™½åå–®è¦å‰‡æ‡‰ç”¨åˆ°é æ¸¬çµæœä¸Šï¼Œå¯ä¿®æ­£ False Positivesã€‚
    å¯ç¨ç«‹ä½¿ç”¨ï¼Œåªéœ€æä¾› DataFrame å’Œè¦å‰‡åˆ—è¡¨å³å¯ã€‚
    
    >>> import pandas as pd
    >>> import numpy as np
    >>> 
    >>> df = pd.DataFrame({'Proto': ['TCP'], 'Dport': [80]})
    >>> y_pred = np.array([1])
    >>> rules = [("TCP/80", {'type': 'proto_port', 'proto': 'tcp', 'port': 80.0}, 0.1, 0.05, 0.01)]
    >>> applier = WhitelistApplier(verbose=False)
    >>> y_filtered, stats = applier.apply_rules(y_pred, df, rules)
    >>> len(y_filtered) == len(y_pred)
    True
    """
    
    def __init__(
        self,
        verbose: bool = True,
        use_anomaly_score_filter: bool = True,
        anomaly_score_percentile: float = 75.0
    ):
        """
        åˆå§‹åŒ–æ‡‰ç”¨å™¨
        
        Args:
            verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
            use_anomaly_score_filter: æ˜¯å¦ä½¿ç”¨ç•°å¸¸åˆ†æ•¸éæ¿¾ï¼ˆé è¨­ Trueï¼Œä½†å¯ä»¥è¨­ç‚º False å®Œå…¨ç§»é™¤é™åˆ¶ï¼‰
            anomaly_score_percentile: ç•°å¸¸åˆ†æ•¸åˆ†ä½æ•¸ï¼ˆé è¨­ 75.0ï¼Œå³ 75% åˆ†ä½æ•¸ï¼‰
        """
        self.verbose = verbose
        self.use_anomaly_score_filter = use_anomaly_score_filter
        self.anomaly_score_percentile = anomaly_score_percentile
    
    def apply_rules(
        self,
        y_pred: np.ndarray,
        features_df: pd.DataFrame,
        whitelist_rules: List[Tuple[str, dict, float, float, float]],
        anomaly_scores: Optional[np.ndarray] = None,
        cleaned_df: Optional[pd.DataFrame] = None,
        test_idx: Optional[pd.Index] = None,
        y_true: Optional[np.ndarray] = None
    ) -> Tuple[np.ndarray, dict]:
        """
        æ‡‰ç”¨ç™½åå–®è¦å‰‡åˆ°é æ¸¬çµæœ
        
        å¯ç¨ç«‹ä½¿ç”¨ï¼Œåªéœ€æä¾›é æ¸¬çµæœã€ç‰¹å¾µå’Œè¦å‰‡ã€‚
        ä¸»è¦ç”¨æ–¼ä¿®æ­£ False Positivesï¼ˆå°‡è¢«èª¤åˆ¤ç‚ºç•°å¸¸çš„æ­£å¸¸æµé‡æ¨™è¨˜ç‚ºæ­£å¸¸ï¼‰ã€‚
        
        Args:
            y_pred: åŸå§‹é æ¸¬çµæœï¼ˆ1=ç•°å¸¸, 0=æ­£å¸¸ï¼‰
            features_df: ç‰¹å¾µ DataFrame
            whitelist_rules: ç™½åå–®è¦å‰‡åˆ—è¡¨
            anomaly_scores: ç•°å¸¸åˆ†æ•¸ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ›´ç²¾ç¢ºçš„ç™½åå–®æ‡‰ç”¨ï¼‰
            cleaned_df: æ¸…æ´—å¾Œçš„åŸå§‹ DataFrameï¼ˆå¯é¸ï¼Œç”¨æ–¼ç²å–ç¼ºå¤±æ¬„ä½ï¼‰
            test_idx: æ¸¬è©¦é›†ç´¢å¼•ï¼ˆå¯é¸ï¼Œç”¨æ–¼å¾ cleaned_df ç²å–è³‡æ–™ï¼‰
            y_true: çœŸå¯¦æ¨™ç±¤ï¼ˆå¯é¸ï¼Œç”¨æ–¼è¨ˆç®—æ•ˆæœï¼‰
        
        Returns:
            (ä¿®æ­£å¾Œçš„é æ¸¬çµæœ, æ•ˆæœçµ±è¨ˆå­—å…¸)
        """
        if not whitelist_rules:
            return y_pred, {}
        
        if self.verbose:
            print("\n[æ‡‰ç”¨ç™½åå–®è¦å‰‡]...")
        
        # é©—è­‰è¼¸å…¥
        if len(y_pred) != len(features_df):
            raise ValueError(f"y_pred é•·åº¦ ({len(y_pred)}) èˆ‡ features_df é•·åº¦ ({len(features_df)}) ä¸ä¸€è‡´")
        
        # ç²å–åŸå§‹è³‡è¨Šï¼ˆé‡ç½®ç´¢å¼•ç‚ºä½ç½®ç´¢å¼•ï¼Œé¿å…ç´¢å¼•å°é½Šå•é¡Œï¼‰
        original_info = features_df.reset_index(drop=True).copy()
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = ['Proto', 'Dport']
        missing_cols = [col for col in required_cols if col not in original_info.columns]
        
        if missing_cols and cleaned_df is not None and test_idx is not None:
            try:
                if isinstance(test_idx, pd.RangeIndex) or (hasattr(test_idx, 'is_monotonic_increasing') and test_idx.is_monotonic_increasing and len(test_idx) == len(original_info)):
                    cleaned_test = cleaned_df.iloc[test_idx].reset_index(drop=True)
                else:
                    cleaned_test = cleaned_df.loc[test_idx].reset_index(drop=True)
                
                for col in missing_cols:
                    if col in cleaned_test.columns:
                        original_info[col] = cleaned_test[col].values
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸  å¾ cleaned_df ç²å–æ¬„ä½æ™‚å‡ºéŒ¯ï¼š{e}")
        
        # åˆä½µæ‰€æœ‰ç™½åå–®é®ç½©
        whitelist_mask = np.zeros(len(original_info), dtype=bool)
        
        if self.verbose:
            print(f"   ğŸ“‹ æ‡‰ç”¨ {len(whitelist_rules)} å€‹ç™½åå–®è¦å‰‡ï¼š")
        
        # è¨ˆç®—ç•°å¸¸åˆ†æ•¸é–¾å€¼ï¼ˆç”¨æ–¼éæ¿¾é«˜ç½®ä¿¡åº¦çš„ç•°å¸¸é æ¸¬ï¼‰
        # ç­–ç•¥ï¼šåªå°åˆ†æ•¸æ¥è¿‘é–¾å€¼çš„ç•°å¸¸é æ¸¬æ‡‰ç”¨ç™½åå–®ï¼ˆé€™äº›æ˜¯é‚Šç·£æ¡ˆä¾‹ï¼Œæ›´å¯èƒ½æ˜¯ FPï¼‰
        if self.use_anomaly_score_filter and anomaly_scores is not None:
            predicted_anomaly_mask = (y_pred == 1)
            if predicted_anomaly_mask.sum() > 0:
                # è¨ˆç®—è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡çš„åˆ†æ•¸åˆ†ä½ˆ
                anomaly_scores_only = anomaly_scores[predicted_anomaly_mask]
                # ä½¿ç”¨æŒ‡å®šåˆ†ä½æ•¸ä½œç‚ºä¸Šé™ï¼ˆåªå°åˆ†æ•¸è¼ƒä½çš„ç•°å¸¸é æ¸¬æ‡‰ç”¨ç™½åå–®ï¼‰
                # é€™äº›æ˜¯ã€Œä¸å¤ªç¢ºå®šã€çš„ç•°å¸¸é æ¸¬ï¼Œæ›´å¯èƒ½æ˜¯ FP
                score_threshold = np.percentile(anomaly_scores_only, self.anomaly_score_percentile)
                if self.verbose:
                    print(f"   ğŸ’¡ ç•°å¸¸åˆ†æ•¸é–¾å€¼ï¼š{score_threshold:.4f} (åªå°è¢«é æ¸¬ç‚ºç•°å¸¸ä¸”åˆ†æ•¸ < {score_threshold:.4f} çš„æµé‡æ‡‰ç”¨ç™½åå–®)")
                    low_score_anomalies = ((anomaly_scores < score_threshold) & predicted_anomaly_mask).sum()
                    total_anomalies = predicted_anomaly_mask.sum()
                    print(f"   ğŸ“Š è¢«é æ¸¬ç‚ºç•°å¸¸ä¸”åˆ†æ•¸ < é–¾å€¼çš„æµé‡ï¼š{low_score_anomalies:,} / {total_anomalies:,} ({low_score_anomalies/total_anomalies*100:.1f}%)")
            else:
                score_threshold = None
                if self.verbose:
                    print(f"   âš ï¸  æ²’æœ‰è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡ï¼Œè·³éç•°å¸¸åˆ†æ•¸æª¢æŸ¥")
        elif not self.use_anomaly_score_filter:
            score_threshold = None
            if self.verbose:
                print(f"   ğŸ’¡ ä¸ä½¿ç”¨ç•°å¸¸åˆ†æ•¸éæ¿¾ï¼ˆåŸºæ–¼è¦å‰‡åŒ¹é…å³å¯ï¼‰")
        else:
            score_threshold = None
            if self.verbose:
                print(f"   âš ï¸  æœªæä¾›ç•°å¸¸åˆ†æ•¸ï¼Œä¸é€²è¡Œåˆ†æ•¸éæ¿¾")
        
        # æ‡‰ç”¨æ¯å€‹è¦å‰‡
        for rule_name, rule_params, fp_ratio, normal_ratio, attack_ratio in whitelist_rules:
            rule_mask = self._create_rule_mask(rule_params, original_info)
            
            # æ‡‰ç”¨è¡Œç‚ºç‰¹å¾µæ¢ä»¶
            behavioral_conditions = rule_params.get('behavioral_conditions', {})
            if behavioral_conditions:
                initial_count = rule_mask.sum()
                for feat, cond in behavioral_conditions.items():
                    feat_name = None
                    if feat in original_info.columns:
                        feat_name = feat
                    elif f'log_{feat}' in original_info.columns:
                        feat_name = f'log_{feat}'
                    
                    if feat_name:
                        feat_values = original_info[feat_name].values
                        if 'max' in cond:
                            feat_mask = (feat_values < cond['max']) | np.isnan(feat_values)
                            rule_mask = rule_mask & feat_mask
                        elif 'min' in cond:
                            feat_mask = (feat_values > cond['min']) | np.isnan(feat_values)
                            rule_mask = rule_mask & feat_mask
                
                if self.verbose and initial_count > rule_mask.sum():
                    behavioral_filtered = initial_count - rule_mask.sum()
                    print(f"         (è¡Œç‚ºç‰¹å¾µéæ¿¾ï¼š{initial_count:,} â†’ {rule_mask.sum():,}, éæ¿¾ {behavioral_filtered:,} ç­†)")
            
            # æ‡‰ç”¨ç•°å¸¸åˆ†æ•¸é–¾å€¼ï¼ˆåªå°è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡é€²è¡Œåˆ†æ•¸éæ¿¾ï¼‰
            rule_anomaly_threshold = rule_params.get('anomaly_score_threshold', score_threshold)
            if self.use_anomaly_score_filter and anomaly_scores is not None and rule_anomaly_threshold is not None:
                if len(anomaly_scores) == len(rule_mask):
                    # åªå°è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡æ‡‰ç”¨åˆ†æ•¸éæ¿¾
                    predicted_anomaly_mask = (y_pred == 1)
                    # å°æ–¼è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡ï¼Œåªä¿ç•™åˆ†æ•¸ < é–¾å€¼çš„ï¼ˆé‚Šç·£æ¡ˆä¾‹ï¼‰
                    # å°æ–¼è¢«é æ¸¬ç‚ºæ­£å¸¸çš„æµé‡ï¼Œä¸é€²è¡Œåˆ†æ•¸éæ¿¾
                    low_score_mask = (
                        (~predicted_anomaly_mask) |  # æ­£å¸¸é æ¸¬ï¼šä¸é€²è¡Œåˆ†æ•¸éæ¿¾
                        (predicted_anomaly_mask & (anomaly_scores < rule_anomaly_threshold))  # ç•°å¸¸é æ¸¬ï¼šåªä¿ç•™ä½åˆ†æ•¸çš„
                    )
                    total_matched = rule_mask.sum()
                    rule_mask = rule_mask & low_score_mask
                    filtered_count = rule_mask.sum()
                    if self.verbose and total_matched > filtered_count:
                        score_filtered = total_matched - filtered_count
                        print(f"         (ç•°å¸¸åˆ†æ•¸éæ¿¾ï¼š{total_matched:,} â†’ {filtered_count:,}, éæ¿¾ {score_filtered:,} ç­†)")
                    elif self.verbose and not behavioral_conditions:
                        print(f"      - {rule_name}: {filtered_count:,} ç­†æµé‡")
                elif self.verbose:
                    print(f"      âš ï¸  ç•°å¸¸åˆ†æ•¸é•·åº¦ä¸åŒ¹é…ï¼š{len(anomaly_scores)} vs {len(rule_mask)}ï¼Œè·³éç•°å¸¸åˆ†æ•¸æª¢æŸ¥")
                    print(f"      - {rule_name}: {rule_mask.sum():,} ç­†æµé‡")
            elif self.verbose and not behavioral_conditions:
                print(f"      - {rule_name}: {rule_mask.sum():,} ç­†æµé‡")
            
            whitelist_mask = whitelist_mask | rule_mask
        
        num_whitelisted = whitelist_mask.sum()
        if self.verbose:
            print(f"   ğŸ›¡ï¸  ç¬¦åˆç™½åå–®è¦å‰‡çš„æµé‡ç¸½æ•¸ï¼š{num_whitelisted:,}")
        
        # ğŸ”§ é—œéµä¿®æ­£ï¼šåªå°è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡æ‡‰ç”¨ç™½åå–®
        # ç™½åå–®çš„ç›®çš„æ˜¯ä¿®æ­£ FPï¼ˆå°‡èª¤åˆ¤ç‚ºç•°å¸¸çš„æ­£å¸¸æµé‡æ”¹ç‚ºæ­£å¸¸ï¼‰
        # æ‰€ä»¥åªæ‡‰ç”¨åˆ° y_pred == 1 çš„æµé‡
        predicted_anomaly_mask = (y_pred == 1)
        whitelist_mask = whitelist_mask & predicted_anomaly_mask
        
        num_whitelisted_anomalies = whitelist_mask.sum()
        if self.verbose:
            print(f"   ğŸ” å…¶ä¸­è¢«é æ¸¬ç‚ºç•°å¸¸çš„æµé‡ï¼š{num_whitelisted_anomalies:,} ç­†")
            if num_whitelisted > 0:
                anomaly_ratio = num_whitelisted_anomalies / num_whitelisted * 100
                print(f"   ğŸ“Š ç¬¦åˆè¦å‰‡çš„æµé‡ä¸­è¢«é æ¸¬ç‚ºç•°å¸¸çš„æ¯”ä¾‹ï¼š{anomaly_ratio:.1f}%")
        
        # æ‡‰ç”¨ç™½åå–®ï¼ˆå°‡ç¬¦åˆè¦å‰‡çš„ç•°å¸¸é æ¸¬æ”¹ç‚ºæ­£å¸¸ï¼‰
        y_pred_original = y_pred.copy()
        y_pred_filtered = y_pred.copy()
        y_pred_filtered[whitelist_mask] = 0
        
        # è¨ˆç®—æ•ˆæœçµ±è¨ˆ
        stats = {
            'original_anomalies': int(y_pred_original.sum()),
            'filtered_anomalies': int(y_pred_filtered.sum()),
            'reduced_anomalies': int(y_pred_original.sum() - y_pred_filtered.sum()),
            'whitelisted_count': int(num_whitelisted)
        }
        
        if y_true is not None:
            if isinstance(y_true, pd.Series):
                y_true = y_true.values
            elif not isinstance(y_true, np.ndarray):
                y_true = np.array(y_true)
            
            if len(y_true) == len(y_pred_original):
                rescued_fp = ((y_pred_original == 1) & (y_true == 0) & whitelist_mask).sum()
                wrongly_whitelisted = ((y_pred_original == 1) & (y_true == 1) & whitelist_mask).sum()
                stats['rescued_fp'] = int(rescued_fp)
                stats['wrongly_whitelisted'] = int(wrongly_whitelisted)
                
                if self.verbose:
                    print(f"   ğŸ“‰ æˆåŠŸæ¶ˆé™¤çš„ False Positivesï¼š{rescued_fp:,}")
                    if wrongly_whitelisted > 0:
                        print(f"   âš ï¸  èª¤å°‡æ”»æ“Šè€…æ”¾å…¥ç™½åå–®ï¼š{wrongly_whitelisted:,}")
                    else:
                        print(f"   âœ… æœªèª¤æ®ºä»»ä½•çœŸå¯¦æ”»æ“Š")
        
        if self.verbose:
            print(f"   ğŸ“Š ä¿®æ­£å¾Œçš„é æ¸¬ç•°å¸¸æ•¸é‡ï¼š{y_pred_filtered.sum():,} (åŸï¼š{y_pred_original.sum():,})")
            print(f"   ğŸ“‰ æ¸›å°‘ç•°å¸¸é æ¸¬ï¼š{stats['reduced_anomalies']:,} ç­†")
        
        return y_pred_filtered, stats
    
    def _create_rule_mask(
        self,
        rule_params: dict,
        original_info: pd.DataFrame
    ) -> np.ndarray:
        """
        æ ¹æ“šè¦å‰‡åƒæ•¸å‰µå»ºé®ç½©
        
        Args:
            rule_params: è¦å‰‡åƒæ•¸å­—å…¸
            original_info: ç‰¹å¾µ DataFrame
        
        Returns:
            å¸ƒæ—é®ç½©é™£åˆ—
        """
        rule_type = rule_params.get('type')
        
        if rule_type == 'proto_port' or rule_type == 'proto_port_behavioral':
            proto = rule_params.get('proto')
            port = rule_params.get('port')
            if 'Proto' in original_info.columns and 'Dport' in original_info.columns:
                rule_mask = (
                    (original_info['Proto'].str.lower() == proto).values & 
                    (original_info['Dport'].astype(float) == port).values
                )
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        
        elif rule_type == 'port' or rule_type == 'port_behavioral':
            port = rule_params.get('port')
            if 'Dport' in original_info.columns:
                rule_mask = (original_info['Dport'].astype(float) == port).values
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        
        elif rule_type == 'proto_ip':
            proto = rule_params.get('proto')
            ip = rule_params.get('ip')
            if 'Proto' in original_info.columns and 'DstAddr' in original_info.columns:
                rule_mask = (
                    (original_info['Proto'].str.lower() == proto).values & 
                    (original_info['DstAddr'] == ip).values
                )
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        
        elif rule_type == 'proto_port_ip':
            proto = rule_params.get('proto')
            port = rule_params.get('port')
            ip = rule_params.get('ip')
            if 'Proto' in original_info.columns and 'Dport' in original_info.columns and 'DstAddr' in original_info.columns:
                rule_mask = (
                    (original_info['Proto'].str.lower() == proto).values & 
                    (original_info['Dport'].astype(float) == port).values &
                    (original_info['DstAddr'] == ip).values
                )
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        
        elif rule_type == 'proto_port_range':
            proto = rule_params.get('proto')
            port_min = rule_params.get('port_min')
            port_max = rule_params.get('port_max')
            if 'Proto' in original_info.columns and 'Dport' in original_info.columns:
                rule_mask = (
                    (original_info['Proto'].str.lower() == proto).values & 
                    (original_info['Dport'].astype(float) >= port_min).values &
                    (original_info['Dport'].astype(float) <= port_max).values
                )
            else:
                rule_mask = np.zeros(len(original_info), dtype=bool)
        
        else:
            rule_mask = np.zeros(len(original_info), dtype=bool)
        
        return rule_mask


if __name__ == '__main__':
    # ç°¡å–®æ¸¬è©¦
    import doctest
    import sys
    import os
    
    # å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥ Python è·¯å¾‘ï¼Œä»¥ä¾¿æ­£ç¢ºåŒ¯å…¥æ¨¡çµ„
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    doctest.testmod(verbose=True)

