"""
ç™½åå–®å¾Œè™•ç†ï¼šåˆ†æ False Positives ä¸¦æ‡‰ç”¨ç™½åå–®è¦å‰‡

æ­¤è…³æœ¬å°ˆæ³¨æ–¼æ¨¡å‹é æ¸¬çš„å¾Œè™•ç†ï¼Œéµå¾ªå–®ä¸€è·è²¬åŸå‰‡ã€‚
éœ€è¦å…ˆåŸ·è¡Œ train_unsupervised.py ç”Ÿæˆè¨“ç·´çµæœã€‚

æ­¤è…³æœ¬æ”¯æ´ä¸‰ç¨®ç™½åå–®è¦å‰‡ç”Ÿæˆæ–¹æ³•ï¼š
1. å›ºå®šé–¾å€¼æ–¹æ³•ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰
2. è©•åˆ†æ–¹æ³• + Top-N
3. è©•åˆ†æ–¹æ³• + è©•åˆ†é–¾å€¼
"""
import sys
import time
import pickle
import json
from pathlib import Path
from typing import Optional, List, Dict, Any

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥ Python è·¯å¾‘ï¼ˆå¿…é ˆåœ¨åŒ¯å…¥ src æ¨¡çµ„ä¹‹å‰ï¼‰
PROJECT_ROOT = Path(__file__).parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src import (
    DataLoaderFactory,
    DataSourceType,
    WhitelistAnalyzer,
    WhitelistApplier,
    evaluate_and_print,
    compare_metrics
)
from sklearn.metrics import classification_report
import numpy as np
import pandas as pd

# ============================================================================
# ğŸ”§ æ¸¬è©¦é…ç½®ï¼šé¸æ“‡è¦æ¸¬è©¦çš„æ–¹æ³•ï¼ˆä¿®æ”¹æ­¤è®Šé‡ä¾†åˆ‡æ›æ–¹æ³•ï¼‰
# ============================================================================
# é¸é …ï¼š
#   "threshold"     - æ–¹æ³• 1ï¼šå›ºå®šé–¾å€¼æ–¹æ³•ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰
#   "scoring_topn"  - æ–¹æ³• 2ï¼šè©•åˆ†æ–¹æ³• + Top-N
#   "scoring_threshold" - æ–¹æ³• 3ï¼šè©•åˆ†æ–¹æ³• + è©•åˆ†é–¾å€¼
WHITELIST_METHOD = "scoring_threshold"  # é è¨­ä½¿ç”¨è©•åˆ†é–¾å€¼æ–¹æ³•

# æ–¹æ³• 2 çš„åƒæ•¸ï¼ˆç•¶ WHITELIST_METHOD == "scoring_topn" æ™‚ä½¿ç”¨ï¼‰
SCORING_TOP_N = 20  # Top-N å€‹çµ„åˆ
SCORING_MIN_SAMPLES = 50  # æœ€å°æ¨£æœ¬é‡è¦æ±‚

# æ–¹æ³• 3 çš„åƒæ•¸ï¼ˆç•¶ WHITELIST_METHOD == "scoring_threshold" æ™‚ä½¿ç”¨ï¼‰
SCORING_THRESHOLD = 0.3  # è©•åˆ†é–¾å€¼
SCORING_MIN_SAMPLES_THRESHOLD = 50  # æœ€å°æ¨£æœ¬é‡è¦æ±‚

# ============================================================================


def load_training_results(input_dir: Path) -> Dict[str, Any]:
    """
    è¼‰å…¥è¨“ç·´çµæœ
    
    Args:
        input_dir: è¨“ç·´çµæœç›®éŒ„
    
    Returns:
        åŒ…å«æ‰€æœ‰è¨“ç·´çµæœçš„å­—å…¸
    """
    if not input_dir.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ°è¨“ç·´çµæœç›®éŒ„: {input_dir}\n"
            f"è«‹å…ˆåŸ·è¡Œ train_unsupervised.py ç”Ÿæˆè¨“ç·´çµæœã€‚"
        )
    
    results = {}
    
    # è¼‰å…¥é…ç½®
    with open(input_dir / "config.json", "r") as f:
        results["config"] = json.load(f)
    
    use_protocol_grouping = results["config"]["use_protocol_grouping"]
    
    # è¼‰å…¥æ¨¡å‹
    if use_protocol_grouping:
        with open(input_dir / "protocol_models.pkl", "rb") as f:
            results["protocol_models"] = pickle.load(f)
        if (input_dir / "protocol_scalers.pkl").exists():
            with open(input_dir / "protocol_scalers.pkl", "rb") as f:
                results["protocol_scalers"] = pickle.load(f)
    else:
        with open(input_dir / "model.pkl", "rb") as f:
            results["model"] = pickle.load(f)
        if (input_dir / "scaler.pkl").exists():
            with open(input_dir / "scaler.pkl", "rb") as f:
                results["scaler"] = pickle.load(f)
    
    # è¼‰å…¥ç‰¹å¾µè³‡æ–™
    if (input_dir / "X_train.parquet").exists():
        results["X_train"] = pd.read_parquet(input_dir / "X_train.parquet")
    if (input_dir / "X_val.parquet").exists():
        results["X_val"] = pd.read_parquet(input_dir / "X_val.parquet")
    if (input_dir / "X_test.parquet").exists():
        results["X_test"] = pd.read_parquet(input_dir / "X_test.parquet")
    
    if (input_dir / "features_df_train.parquet").exists():
        results["features_df_train"] = pd.read_parquet(input_dir / "features_df_train.parquet")
    if (input_dir / "features_df_val.parquet").exists():
        results["features_df_val"] = pd.read_parquet(input_dir / "features_df_val.parquet")
    if (input_dir / "features_df_test.parquet").exists():
        results["features_df_test"] = pd.read_parquet(input_dir / "features_df_test.parquet")
    
    # è¼‰å…¥æ¨™ç±¤å’Œç•°å¸¸åˆ†æ•¸
    if (input_dir / "y_train.npy").exists():
        results["y_train"] = np.load(input_dir / "y_train.npy")
    if (input_dir / "y_val.npy").exists():
        results["y_val"] = np.load(input_dir / "y_val.npy")
    if (input_dir / "y_test.npy").exists():
        results["y_test"] = np.load(input_dir / "y_test.npy")
    
    if (input_dir / "train_anomaly_scores.npy").exists():
        results["train_anomaly_scores"] = np.load(input_dir / "train_anomaly_scores.npy")
    if (input_dir / "val_anomaly_scores.npy").exists():
        results["val_anomaly_scores"] = np.load(input_dir / "val_anomaly_scores.npy")
    if (input_dir / "test_anomaly_scores.npy").exists():
        results["test_anomaly_scores"] = np.load(input_dir / "test_anomaly_scores.npy")
    
    # è¼‰å…¥ feature_robust_scaler
    if (input_dir / "feature_robust_scaler.pkl").exists():
        with open(input_dir / "feature_robust_scaler.pkl", "rb") as f:
            results["feature_robust_scaler"] = pickle.load(f)
    
    return results


def main():
    print("=" * 60)
    print("ç™½åå–®å¾Œè™•ç†ï¼šåˆ†æ False Positives ä¸¦æ‡‰ç”¨ç™½åå–®è¦å‰‡")
    print("=" * 60)
    
    # é¡¯ç¤ºç•¶å‰ä½¿ç”¨çš„ç™½åå–®æ–¹æ³•
    print(f"\nğŸ”§ ç•¶å‰ç™½åå–®æ–¹æ³•ï¼š{WHITELIST_METHOD}")
    if WHITELIST_METHOD == "threshold":
        print("   æ–¹æ³• 1ï¼šå›ºå®šé–¾å€¼æ–¹æ³•ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰")
    elif WHITELIST_METHOD == "scoring_topn":
        print(f"   æ–¹æ³• 2ï¼šè©•åˆ†æ–¹æ³• + Top-N (top_n={SCORING_TOP_N}, min_samples={SCORING_MIN_SAMPLES})")
    elif WHITELIST_METHOD == "scoring_threshold":
        print(f"   æ–¹æ³• 3ï¼šè©•åˆ†æ–¹æ³• + è©•åˆ†é–¾å€¼ (threshold={SCORING_THRESHOLD}, min_samples={SCORING_MIN_SAMPLES_THRESHOLD})")
    print("=" * 60)
    
    # 1. è¼‰å…¥è¨“ç·´çµæœ
    print("\n[æ­¥é©Ÿ 1] è¼‰å…¥è¨“ç·´çµæœ...")
    start_time = time.time()
    
    input_dir = Path("data/models/unsupervised_training")
    results = load_training_results(input_dir)
    
    config = results["config"]
    use_protocol_grouping = config["use_protocol_grouping"]
    best_threshold = config.get("best_threshold")
    contamination = config.get("contamination", 0.1)
    
    load_time = time.time() - start_time
    print(f"âœ… è¼‰å…¥å®Œæˆï¼ˆè€—æ™‚ {load_time:.2f} ç§’ï¼‰")
    print(f"   ä½¿ç”¨å”è­°åˆ†çµ„ï¼š{use_protocol_grouping}")
    print(f"   æœ€ä½³é–¾å€¼ï¼š{best_threshold}")
    print(f"   Contaminationï¼š{contamination}")
    
    # 2. è¼‰å…¥åŸå§‹è³‡æ–™ï¼ˆç”¨æ–¼ç™½åå–®åˆ†æï¼‰
    print("\n[æ­¥é©Ÿ 2] è¼‰å…¥åŸå§‹è³‡æ–™ï¼ˆç”¨æ–¼ç™½åå–®åˆ†æï¼‰...")
    
    parquet_path = Path("data/processed/capture20110817_cleaned_spark.parquet")
    if not parquet_path.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ° Parquet æª”æ¡ˆ: {parquet_path}\n"
            f"è«‹å…ˆåŸ·è¡Œè³‡æ–™è™•ç†è…³æœ¬ç”Ÿæˆ Parquet æª”æ¡ˆã€‚"
        )
    
    raw_df = pd.read_parquet(parquet_path, engine='pyarrow')
    loader = DataLoaderFactory.create(DataSourceType.BIDIRECTIONAL_BINETFLOW)
    cleaned_df = loader.clean(raw_df)
    
    print(f"âœ… åŸå§‹è³‡æ–™è¼‰å…¥å®Œæˆï¼š{len(cleaned_df):,} ç­†è³‡æ–™")
    
    # 3. æº–å‚™è³‡æ–™
    print("\n[æ­¥é©Ÿ 3] æº–å‚™è³‡æ–™...")
    
    X_train = results.get("X_train")
    X_test = results.get("X_test")
    features_df_train = results.get("features_df_train")
    features_df_test = results.get("features_df_test")
    y_train = results.get("y_train")
    y_test = results.get("y_test")
    train_anomaly_scores = results.get("train_anomaly_scores")
    test_anomaly_scores = results.get("test_anomaly_scores")
    
    if X_train is None or features_df_train is None:
        raise ValueError("ç¼ºå°‘è¨“ç·´é›†è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œç™½åå–®åˆ†æ")
    if X_test is None or features_df_test is None:
        raise ValueError("ç¼ºå°‘æ¸¬è©¦é›†è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œè©•ä¼°")
    
    # ç²å–ç´¢å¼•ï¼ˆç”¨æ–¼å¾ cleaned_df ç²å–è³‡æ–™ï¼‰
    train_idx = features_df_train.index if hasattr(features_df_train.index, 'tolist') else None
    test_idx = features_df_test.index if hasattr(features_df_test.index, 'tolist') else None
    
    print(f"âœ… è³‡æ–™æº–å‚™å®Œæˆ")
    print(f"   è¨“ç·´é›†ï¼š{len(X_train):,} ç­†")
    print(f"   æ¸¬è©¦é›†ï¼š{len(X_test):,} ç­†")
    
    # 4. åœ¨è¨“ç·´é›†ä¸Šç”Ÿæˆé æ¸¬ï¼ˆç”¨æ–¼ FP åˆ†æï¼‰
    print("\n[æ­¥é©Ÿ 4] åœ¨è¨“ç·´é›†ä¸Šç”Ÿæˆé æ¸¬ï¼ˆç”¨æ–¼ FP åˆ†æï¼‰...")
    
    if train_anomaly_scores is None:
        raise ValueError("ç¼ºå°‘è¨“ç·´é›†ç•°å¸¸åˆ†æ•¸ï¼Œç„¡æ³•é€²è¡Œç™½åå–®åˆ†æ")
    
    # ä½¿ç”¨ contamination ç™¾åˆ†ä½æ•¸ä½œç‚ºè‡¨æ™‚é–¾å€¼ï¼ˆç”¨æ–¼åˆ†æï¼‰
    temp_threshold = np.percentile(train_anomaly_scores, 100 * (1 - contamination))
    y_pred_train = (train_anomaly_scores >= temp_threshold).astype(int)
    
    print(f"   è¨“ç·´é›†é æ¸¬ç•°å¸¸æ•¸é‡ï¼š{y_pred_train.sum():,} ({y_pred_train.sum()/len(y_pred_train)*100:.2f}%)")
    
    # 5. åˆ†æè¨“ç·´é›†ä¸Šçš„ False Positivesï¼ˆæ­¸ç´ç™½åå–®è¦å‰‡ï¼‰
    print("\n[æ­¥é©Ÿ 5] åˆ†æè¨“ç·´é›†ä¸Šçš„ False Positives æ¨¡å¼...")
    
    whitelist_rules = []
    if y_train is not None:
        # è¨ˆç®—ç•°å¸¸åˆ†æ•¸é–¾å€¼ï¼ˆç”¨æ–¼æ›´ç²¾ç¢ºçš„ç™½åå–®æ‡‰ç”¨ï¼‰
        anomaly_score_threshold = np.percentile(train_anomaly_scores, 25)
        
        # ä½¿ç”¨ WhitelistAnalyzer åˆ†æ FP æ¨¡å¼
        print(f"\n   ğŸ”§ ä½¿ç”¨ç™½åå–®æ–¹æ³•ï¼š{WHITELIST_METHOD}")
        
        if WHITELIST_METHOD == "threshold":
            analyzer = WhitelistAnalyzer(
                fp_ratio_threshold=0.01,
                normal_ratio_threshold=0.01,
                attack_ratio_threshold=0.03,
                anomaly_score_threshold=anomaly_score_threshold,
                use_scoring_method=False,
                verbose=True
            )
        elif WHITELIST_METHOD == "scoring_topn":
            analyzer = WhitelistAnalyzer(
                normal_ratio_threshold=0.01,
                attack_ratio_threshold=0.03,
                anomaly_score_threshold=anomaly_score_threshold,
                use_scoring_method=True,
                top_n_combos=SCORING_TOP_N,
                min_combo_samples=SCORING_MIN_SAMPLES,
                verbose=True
            )
        elif WHITELIST_METHOD == "scoring_threshold":
            analyzer = WhitelistAnalyzer(
                normal_ratio_threshold=0.01,
                attack_ratio_threshold=0.03,
                anomaly_score_threshold=anomaly_score_threshold,
                use_scoring_method=True,
                score_threshold=SCORING_THRESHOLD,
                min_combo_samples=SCORING_MIN_SAMPLES_THRESHOLD,
                verbose=True
            )
        else:
            raise ValueError(f"æœªçŸ¥çš„ç™½åå–®æ–¹æ³•ï¼š{WHITELIST_METHOD}")
        
        whitelist_rules = analyzer.analyze_fp_patterns(
            features_df_train,
            y_pred_train,
            y_train,
            anomaly_scores=train_anomaly_scores,
            cleaned_df=cleaned_df,
            train_idx=train_idx
        )
        
        print(f"\n   âœ… ç™½åå–®è¦å‰‡ç”Ÿæˆå®Œæˆï¼šå…± {len(whitelist_rules)} æ¢è¦å‰‡")
    else:
        print("\n[æ­¥é©Ÿ 5] è·³é FP åˆ†æï¼ˆç„¡æ¨™ç±¤è³‡æ–™ï¼‰...")
    
    # 6. åœ¨æ¸¬è©¦é›†ä¸Šç”Ÿæˆé æ¸¬
    print("\n[æ­¥é©Ÿ 6] åœ¨æ¸¬è©¦é›†ä¸Šç”Ÿæˆé æ¸¬...")
    
    if test_anomaly_scores is None:
        raise ValueError("ç¼ºå°‘æ¸¬è©¦é›†ç•°å¸¸åˆ†æ•¸ï¼Œç„¡æ³•é€²è¡Œè©•ä¼°")
    
    # ä½¿ç”¨æœ€ä½³é–¾å€¼ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦å‰‡ä½¿ç”¨ contamination ç™¾åˆ†ä½æ•¸
    if best_threshold is not None:
        print(f"   âœ… ä½¿ç”¨è¨“ç·´æ™‚æ‰¾åˆ°çš„æœ€ä½³é–¾å€¼ï¼š{best_threshold:.4f}")
        y_pred_test = (test_anomaly_scores >= best_threshold).astype(int)
    else:
        threshold_test = np.percentile(test_anomaly_scores, 100 * (1 - contamination))
        print(f"   âš ï¸  ä½¿ç”¨ contamination ç™¾åˆ†ä½æ•¸é–¾å€¼ï¼š{threshold_test:.4f}")
        y_pred_test = (test_anomaly_scores >= threshold_test).astype(int)
    
    print(f"   æ¸¬è©¦é›†é æ¸¬ç•°å¸¸æ•¸é‡ï¼š{y_pred_test.sum():,} ({y_pred_test.sum()/len(y_pred_test)*100:.2f}%)")
    
    # 7. æ‡‰ç”¨ç™½åå–®è¦å‰‡
    print("\n[æ­¥é©Ÿ 7] æ‡‰ç”¨ç™½åå–®è¦å‰‡...")
    
    # ç¢ºä¿ features_df_test æŒ‰ç…§ X_test çš„é †åºæ’åˆ—
    features_df_test_aligned = features_df_test.loc[X_test.index].reset_index(drop=True) if hasattr(X_test, 'index') else features_df_test.reset_index(drop=True)
    
    applier = WhitelistApplier(
        verbose=True,
        use_anomaly_score_filter=False,
        anomaly_score_percentile=90.0
    )
    
    y_pred_test_filtered, whitelist_stats = applier.apply_rules(
        y_pred_test,
        features_df_test_aligned,
        whitelist_rules,
        anomaly_scores=test_anomaly_scores,
        cleaned_df=cleaned_df,
        test_idx=test_idx,
        y_true=y_test
    )
    
    # é©—è­‰é †åº
    if y_test is not None:
        assert len(y_pred_test_filtered) == len(y_test), \
            f"é•·åº¦ä¸åŒ¹é…ï¼šy_pred_test_filtered ({len(y_pred_test_filtered)}) vs y_test ({len(y_test)})"
    
    # 8. åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°
    if y_test is not None:
        print("\n[æ­¥é©Ÿ 8] æ¸¬è©¦é›†æ¨¡å‹è©•ä¼°...")
        print("   ğŸ’¡ åœ¨æ¸¬è©¦é›†ä¸Šè©•ä¼°æœ€çµ‚æ€§èƒ½ï¼ˆæœªä½¿ç”¨æ¸¬è©¦é›†æ¨™ç±¤å„ªåŒ–é–¾å€¼ï¼‰...")
        
        # è©•ä¼°åŸå§‹é æ¸¬
        print("\n   ğŸ“Š åŸå§‹é æ¸¬çµæœï¼ˆæœªæ‡‰ç”¨ç™½åå–®ï¼‰ï¼š")
        metrics_original = evaluate_and_print(
            y_test, y_pred_test,
            show_confusion_matrix=True,
            show_summary=True
        )
        
        # è©•ä¼°æ‡‰ç”¨ç™½åå–®å¾Œçš„é æ¸¬
        print("\n   ğŸ“Š æ‡‰ç”¨ç™½åå–®å¾Œçš„é æ¸¬çµæœï¼š")
        metrics_filtered = evaluate_and_print(
            y_test, y_pred_test_filtered,
            show_confusion_matrix=True,
            show_summary=True
        )
        
        # æ¯”è¼ƒæ”¹é€²
        print("\n   ğŸ“ˆ ç™½åå–®æ•ˆæœæ¯”è¼ƒï¼š")
        compare_metrics(metrics_original, metrics_filtered)
        
        print("\nåˆ†é¡å ±å‘Šï¼ˆæ‡‰ç”¨ç™½åå–®å¾Œï¼‰ï¼š")
        print(classification_report(y_test, y_pred_test_filtered, target_names=['æ­£å¸¸', 'ç•°å¸¸'], zero_division=0))
    else:
        print("\n[æ­¥é©Ÿ 8] ç„¡çœŸå¯¦æ¨™ç±¤ï¼Œè·³éè©•ä¼°")
    
    # 9. ä¿å­˜ç™½åå–®å¾Œè™•ç†çµæœï¼ˆä¾›å ±å‘Šç”Ÿæˆå™¨ä½¿ç”¨ï¼‰
    print("\n[æ­¥é©Ÿ 9] ä¿å­˜ç™½åå–®å¾Œè™•ç†çµæœ...")
    
    output_dir = Path("data/models/whitelist_rules")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æº–å‚™ç™½åå–®å¾Œè™•ç†çµæœ
    whitelist_postprocess_results = {
        'original_anomalies': int(whitelist_stats.get('original_anomalies', 0)),
        'final_anomalies': int(whitelist_stats.get('filtered_anomalies', 0)),
        'filtered_count': int(whitelist_stats.get('reduced_anomalies', 0)),
        'total_samples': len(y_pred_test),
        'rule_count': len(whitelist_rules),
        'whitelist_method': WHITELIST_METHOD,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # å¦‚æœæœ‰æ¸¬è©¦é›†è©•ä¼°çµæœï¼Œä¹Ÿä¿å­˜æŒ‡æ¨™
    if y_test is not None:
        whitelist_postprocess_results['test_metrics'] = {
            'original': {
                'tn': int(metrics_original.tn),
                'fp': int(metrics_original.fp),
                'fn': int(metrics_original.fn),
                'tp': int(metrics_original.tp),
                'accuracy': float(metrics_original.accuracy),
                'precision': float(metrics_original.precision),
                'recall': float(metrics_original.recall),
                'f1': float(metrics_original.f1)
            },
            'filtered': {
                'tn': int(metrics_filtered.tn),
                'fp': int(metrics_filtered.fp),
                'fn': int(metrics_filtered.fn),
                'tp': int(metrics_filtered.tp),
                'accuracy': float(metrics_filtered.accuracy),
                'precision': float(metrics_filtered.precision),
                'recall': float(metrics_filtered.recall),
                'f1': float(metrics_filtered.f1)
            }
        }
        print(f"   âœ… æ¸¬è©¦é›†è©•ä¼°æŒ‡æ¨™å·²åŒ…å«åœ¨çµæœä¸­")
    
    # ä¿å­˜åˆ° JSON æ–‡ä»¶
    results_path = output_dir / "whitelist_postprocess_results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(whitelist_postprocess_results, f, indent=2, ensure_ascii=False)
    
    print(f"   âœ… ç™½åå–®å¾Œè™•ç†çµæœå·²ä¿å­˜è‡³: {results_path}")
    print(f"      åŸå§‹ç•°å¸¸æ•¸é‡: {whitelist_postprocess_results['original_anomalies']:,}")
    print(f"      éæ¿¾å¾Œç•°å¸¸æ•¸é‡: {whitelist_postprocess_results['final_anomalies']:,}")
    print(f"      éæ¿¾æ‰çš„æ•¸é‡: {whitelist_postprocess_results['filtered_count']:,}")
    print(f"      ç™½åå–®è¦å‰‡æ•¸: {whitelist_postprocess_results['rule_count']}")
    
    total_time = time.time() - start_time
    print("\n" + "=" * 60)
    print(f"âœ… ç™½åå–®å¾Œè™•ç†å®Œæˆï¼ˆç¸½è€—æ™‚ï¼š{total_time:.2f} ç§’ï¼‰")
    print(f"   è¼‰å…¥è¨“ç·´çµæœï¼š{load_time:.2f} ç§’")
    print(f"   ä½¿ç”¨çš„ç™½åå–®æ–¹æ³•ï¼š{WHITELIST_METHOD}")
    print(f"   ç”Ÿæˆçš„ç™½åå–®è¦å‰‡æ•¸ï¼š{len(whitelist_rules)}")
    print("=" * 60)


if __name__ == "__main__":
    main()

